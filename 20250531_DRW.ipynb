{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "a532a883232a4de6bb3a93c9542d6ac4",
            "6e6679524c3c498e9f8138993d72384e",
            "e363c6fe27ce4aeb8bacea9613786f73",
            "b34d0672c2ec43ec9c8b4592b0ed93ec",
            "e34d30b7cf4542e2b8e332cf94b18c63",
            "c52cc0e516344b1694e7fdfe87d5c98d",
            "dec1fd44a6184e1faa39b606b5bfb073",
            "41a82705d75f4f9aa7822d814285dbb0",
            "d1b2a12b402e412f8ddf62db5c111119",
            "7a8b316e2d7b4871908a75ef41c50657",
            "0f100293ac544c3e8615e189a4bb8e00",
            "68872a6012264841a99b87bc27ef3cfa",
            "c6f59ff4de904947893cdcf6630fe500",
            "3fe743c840564e3db58ca640457c6d4f",
            "0e23729589a149b8bbac5abbaf20bd73",
            "bb274a4efe3b461381af9c86ac03d4dd",
            "3828e5a9457d4b808609d568b6aad74a",
            "38feef5be5604414a6c53a7955187953",
            "9f90efa390f947df87fa3e976569a9e6",
            "71c9c27a40da4c6ab8ca86f460e84e5d",
            "8570b29c6c6a48f8872978e6c87833f0",
            "138bfa59102f46deb0686bd14fc7e5ed",
            "86aa95f469d9461bb79fdd7a5caa7105",
            "e6e366575d7f466c8f37731859fc34f2",
            "2d35bccaaaa24a71909163dd2017593d",
            "ed7260bc8da9460f86f278d4928dd679",
            "8b0776cbba2e473380bfb98c15a48c0d",
            "89e5aff0f112449992b3cf3470a4e8f8",
            "6b8b5bab9e4943ebb1c1dda0209ed11b"
          ]
        },
        "id": "gINwh2vyjMMT",
        "outputId": "5dc6320b-a8da-434f-8df1-239015414767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kaggle credentials set.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mahta/Projects/Time-Series-Library/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "# kagglehub.login()\n",
        "# //read from kaggle.json\n",
        "from kagglehub.config import set_kaggle_credentials\n",
        "\n",
        "import json\n",
        "with open('kaggle.json', 'r') as f:\n",
        "    kaggle_creds = json.load(f)\n",
        "    \n",
        "# kagglehub.login(username=kaggle_creds['username'], key=kaggle_creds['key'])\n",
        "set_kaggle_credentials(username=kaggle_creds['username'], api_key=kaggle_creds['key'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "N_oEzmcxjMMU",
        "outputId": "8f81242b-5a58-415b-c478-c8731d20a24a"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "# drw_crypto_market_prediction_path = kagglehub.competition_download('drw-crypto-market-prediction')\n",
        "\n",
        "# print('Data source import complete.')\n",
        "drw_crypto_market_prediction_path = '/Users/mahta/Projects/Time-Series-Library/data/drw-crypto-market-prediction'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/mahta/Projects/Time-Series-Library/data/drw-crypto-market-prediction'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "drw_crypto_market_prediction_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "97En93vRjMMU",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reducing memory usage for: train\n",
            "--- Memory usage before: 96.29 MB\n",
            "--- Memory usage after: 27.08 MB\n",
            "--- Decreased memory usage by 71.9%\n",
            "\n",
            "Reducing memory usage for: test\n",
            "--- Memory usage before: 90.33 MB\n",
            "--- Memory usage after: 22.58 MB\n",
            "--- Decreased memory usage by 75.0%\n",
            "\n",
            "Train= (525887, 23)\n",
            "Test= (538150, 22)\n",
            "There are 22 FEATURES (added back X174)\n",
            "\n",
            "Full data sample weights range: [0.9746, 1.0259]\n",
            "Model 2 (90% Recent) - Using most recent 473299 samples\n",
            "Model 3 (80% Recent) - Using most recent 420710 samples\n",
            "Model 4 (70% Recent) - Using most recent 368121 samples\n",
            "Model 5 (60% Recent) - Using most recent 315533 samples\n",
            "Model 6 (50% Recent) - Using most recent 262944 samples\n",
            "Model 7 (40% Recent) - Using most recent 210355 samples\n",
            "\n",
            "##################################################\n",
            "### Fold 1\n",
            "##################################################\n",
            "\n",
            "--- Model 1 (100% Full Data) ---\n",
            "[0]\tvalidation_0-rmse:1.01065\n",
            "[200]\tvalidation_0-rmse:0.98346\n",
            "[400]\tvalidation_0-rmse:0.96708\n",
            "[600]\tvalidation_0-rmse:0.95485\n",
            "[800]\tvalidation_0-rmse:0.94498\n",
            "[1000]\tvalidation_0-rmse:0.93642\n",
            "[1200]\tvalidation_0-rmse:0.92915\n",
            "[1400]\tvalidation_0-rmse:0.92309\n",
            "[1600]\tvalidation_0-rmse:0.91706\n",
            "[1666]\tvalidation_0-rmse:0.91554\n",
            "\n",
            "--- Model 2 (90% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01073\n",
            "[200]\tvalidation_0-rmse:0.98399\n",
            "[400]\tvalidation_0-rmse:0.96897\n",
            "[600]\tvalidation_0-rmse:0.95729\n",
            "[800]\tvalidation_0-rmse:0.94786\n",
            "[1000]\tvalidation_0-rmse:0.94025\n",
            "[1200]\tvalidation_0-rmse:0.93371\n",
            "[1400]\tvalidation_0-rmse:0.92772\n",
            "[1600]\tvalidation_0-rmse:0.92229\n",
            "[1666]\tvalidation_0-rmse:0.92043\n",
            "\n",
            "--- Model 3 (80% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01074\n",
            "[200]\tvalidation_0-rmse:0.98503\n",
            "[400]\tvalidation_0-rmse:0.97056\n",
            "[600]\tvalidation_0-rmse:0.96016\n",
            "[800]\tvalidation_0-rmse:0.95119\n",
            "[1000]\tvalidation_0-rmse:0.94371\n",
            "[1200]\tvalidation_0-rmse:0.93750\n",
            "[1400]\tvalidation_0-rmse:0.93193\n",
            "[1600]\tvalidation_0-rmse:0.92729\n",
            "[1666]\tvalidation_0-rmse:0.92595\n",
            "\n",
            "--- Model 4 (70% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01085\n",
            "[200]\tvalidation_0-rmse:0.98466\n",
            "[400]\tvalidation_0-rmse:0.97049\n",
            "[600]\tvalidation_0-rmse:0.96081\n",
            "[800]\tvalidation_0-rmse:0.95323\n",
            "[1000]\tvalidation_0-rmse:0.94674\n",
            "[1200]\tvalidation_0-rmse:0.94139\n",
            "[1400]\tvalidation_0-rmse:0.93703\n",
            "[1600]\tvalidation_0-rmse:0.93288\n",
            "[1666]\tvalidation_0-rmse:0.93167\n",
            "\n",
            "--- Model 5 (60% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01091\n",
            "[200]\tvalidation_0-rmse:0.98631\n",
            "[400]\tvalidation_0-rmse:0.97314\n",
            "[600]\tvalidation_0-rmse:0.96398\n",
            "[800]\tvalidation_0-rmse:0.95717\n",
            "[1000]\tvalidation_0-rmse:0.95179\n",
            "[1200]\tvalidation_0-rmse:0.94746\n",
            "[1400]\tvalidation_0-rmse:0.94321\n",
            "[1600]\tvalidation_0-rmse:0.93980\n",
            "[1666]\tvalidation_0-rmse:0.93876\n",
            "\n",
            "--- Model 6 (50% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01136\n",
            "[200]\tvalidation_0-rmse:0.98977\n",
            "[400]\tvalidation_0-rmse:0.97857\n",
            "[600]\tvalidation_0-rmse:0.97065\n",
            "[800]\tvalidation_0-rmse:0.96513\n",
            "[1000]\tvalidation_0-rmse:0.96071\n",
            "[1200]\tvalidation_0-rmse:0.95658\n",
            "[1400]\tvalidation_0-rmse:0.95340\n",
            "[1600]\tvalidation_0-rmse:0.95090\n",
            "[1666]\tvalidation_0-rmse:0.95009\n",
            "\n",
            "--- Model 7 (40% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01183\n",
            "[200]\tvalidation_0-rmse:0.99045\n",
            "[400]\tvalidation_0-rmse:0.98124\n",
            "[600]\tvalidation_0-rmse:0.97507\n",
            "[800]\tvalidation_0-rmse:0.97039\n",
            "[1000]\tvalidation_0-rmse:0.96706\n",
            "[1200]\tvalidation_0-rmse:0.96484\n",
            "[1400]\tvalidation_0-rmse:0.96245\n",
            "[1600]\tvalidation_0-rmse:0.96025\n",
            "[1666]\tvalidation_0-rmse:0.95977\n",
            "\n",
            "##################################################\n",
            "### Fold 2\n",
            "##################################################\n",
            "\n",
            "--- Model 1 (100% Full Data) ---\n",
            "[0]\tvalidation_0-rmse:1.01298\n",
            "[200]\tvalidation_0-rmse:0.98640\n",
            "[400]\tvalidation_0-rmse:0.96970\n",
            "[600]\tvalidation_0-rmse:0.95731\n",
            "[800]\tvalidation_0-rmse:0.94740\n",
            "[1000]\tvalidation_0-rmse:0.93888\n",
            "[1200]\tvalidation_0-rmse:0.93137\n",
            "[1400]\tvalidation_0-rmse:0.92443\n",
            "[1600]\tvalidation_0-rmse:0.91822\n",
            "[1666]\tvalidation_0-rmse:0.91608\n",
            "\n",
            "--- Model 2 (90% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01298\n",
            "[200]\tvalidation_0-rmse:0.98596\n",
            "[400]\tvalidation_0-rmse:0.97093\n",
            "[600]\tvalidation_0-rmse:0.95924\n",
            "[800]\tvalidation_0-rmse:0.94960\n",
            "[1000]\tvalidation_0-rmse:0.94131\n",
            "[1200]\tvalidation_0-rmse:0.93422\n",
            "[1400]\tvalidation_0-rmse:0.92820\n",
            "[1600]\tvalidation_0-rmse:0.92311\n",
            "[1666]\tvalidation_0-rmse:0.92150\n",
            "\n",
            "--- Model 3 (80% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01305\n",
            "[200]\tvalidation_0-rmse:0.98652\n",
            "[400]\tvalidation_0-rmse:0.97126\n",
            "[600]\tvalidation_0-rmse:0.96021\n",
            "[800]\tvalidation_0-rmse:0.95133\n",
            "[1000]\tvalidation_0-rmse:0.94368\n",
            "[1200]\tvalidation_0-rmse:0.93751\n",
            "[1400]\tvalidation_0-rmse:0.93189\n",
            "[1600]\tvalidation_0-rmse:0.92690\n",
            "[1666]\tvalidation_0-rmse:0.92564\n",
            "\n",
            "--- Model 4 (70% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01305\n",
            "[200]\tvalidation_0-rmse:0.98731\n",
            "[400]\tvalidation_0-rmse:0.97229\n",
            "[600]\tvalidation_0-rmse:0.96182\n",
            "[800]\tvalidation_0-rmse:0.95353\n",
            "[1000]\tvalidation_0-rmse:0.94706\n",
            "[1200]\tvalidation_0-rmse:0.94143\n",
            "[1400]\tvalidation_0-rmse:0.93719\n",
            "[1600]\tvalidation_0-rmse:0.93320\n",
            "[1666]\tvalidation_0-rmse:0.93193\n",
            "\n",
            "--- Model 5 (60% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01313\n",
            "[200]\tvalidation_0-rmse:0.98847\n",
            "[400]\tvalidation_0-rmse:0.97494\n",
            "[600]\tvalidation_0-rmse:0.96584\n",
            "[800]\tvalidation_0-rmse:0.95832\n",
            "[1000]\tvalidation_0-rmse:0.95283\n",
            "[1200]\tvalidation_0-rmse:0.94759\n",
            "[1400]\tvalidation_0-rmse:0.94383\n",
            "[1600]\tvalidation_0-rmse:0.94057\n",
            "[1666]\tvalidation_0-rmse:0.93953\n",
            "\n",
            "--- Model 6 (50% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01356\n",
            "[200]\tvalidation_0-rmse:0.99101\n",
            "[400]\tvalidation_0-rmse:0.97955\n",
            "[600]\tvalidation_0-rmse:0.97147\n",
            "[800]\tvalidation_0-rmse:0.96581\n",
            "[1000]\tvalidation_0-rmse:0.96140\n",
            "[1200]\tvalidation_0-rmse:0.95794\n",
            "[1400]\tvalidation_0-rmse:0.95476\n",
            "[1600]\tvalidation_0-rmse:0.95209\n",
            "[1666]\tvalidation_0-rmse:0.95131\n",
            "\n",
            "--- Model 7 (40% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01392\n",
            "[200]\tvalidation_0-rmse:0.99223\n",
            "[400]\tvalidation_0-rmse:0.98237\n",
            "[600]\tvalidation_0-rmse:0.97568\n",
            "[800]\tvalidation_0-rmse:0.97054\n",
            "[1000]\tvalidation_0-rmse:0.96708\n",
            "[1200]\tvalidation_0-rmse:0.96467\n",
            "[1400]\tvalidation_0-rmse:0.96265\n",
            "[1600]\tvalidation_0-rmse:0.96067\n",
            "[1666]\tvalidation_0-rmse:0.96015\n",
            "\n",
            "##################################################\n",
            "### Fold 3\n",
            "##################################################\n",
            "\n",
            "--- Model 1 (100% Full Data) ---\n",
            "[0]\tvalidation_0-rmse:1.00746\n",
            "[200]\tvalidation_0-rmse:0.98004\n",
            "[400]\tvalidation_0-rmse:0.96421\n",
            "[600]\tvalidation_0-rmse:0.95185\n",
            "[800]\tvalidation_0-rmse:0.94162\n",
            "[1000]\tvalidation_0-rmse:0.93262\n",
            "[1200]\tvalidation_0-rmse:0.92593\n",
            "[1400]\tvalidation_0-rmse:0.91936\n",
            "[1600]\tvalidation_0-rmse:0.91313\n",
            "[1666]\tvalidation_0-rmse:0.91113\n",
            "\n",
            "--- Model 2 (90% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00746\n",
            "[200]\tvalidation_0-rmse:0.98047\n",
            "[400]\tvalidation_0-rmse:0.96452\n",
            "[600]\tvalidation_0-rmse:0.95269\n",
            "[800]\tvalidation_0-rmse:0.94268\n",
            "[1000]\tvalidation_0-rmse:0.93432\n",
            "[1200]\tvalidation_0-rmse:0.92755\n",
            "[1400]\tvalidation_0-rmse:0.92142\n",
            "[1600]\tvalidation_0-rmse:0.91603\n",
            "[1666]\tvalidation_0-rmse:0.91426\n",
            "\n",
            "--- Model 3 (80% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00745\n",
            "[200]\tvalidation_0-rmse:0.98103\n",
            "[400]\tvalidation_0-rmse:0.96532\n",
            "[600]\tvalidation_0-rmse:0.95386\n",
            "[800]\tvalidation_0-rmse:0.94525\n",
            "[1000]\tvalidation_0-rmse:0.93835\n",
            "[1200]\tvalidation_0-rmse:0.93212\n",
            "[1400]\tvalidation_0-rmse:0.92648\n",
            "[1600]\tvalidation_0-rmse:0.92156\n",
            "[1666]\tvalidation_0-rmse:0.92005\n",
            "\n",
            "--- Model 4 (70% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00754\n",
            "[200]\tvalidation_0-rmse:0.98137\n",
            "[400]\tvalidation_0-rmse:0.96634\n",
            "[600]\tvalidation_0-rmse:0.95582\n",
            "[800]\tvalidation_0-rmse:0.94748\n",
            "[1000]\tvalidation_0-rmse:0.94161\n",
            "[1200]\tvalidation_0-rmse:0.93580\n",
            "[1400]\tvalidation_0-rmse:0.93138\n",
            "[1600]\tvalidation_0-rmse:0.92701\n",
            "[1666]\tvalidation_0-rmse:0.92555\n",
            "\n",
            "--- Model 5 (60% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00758\n",
            "[200]\tvalidation_0-rmse:0.98242\n",
            "[400]\tvalidation_0-rmse:0.96910\n",
            "[600]\tvalidation_0-rmse:0.95973\n",
            "[800]\tvalidation_0-rmse:0.95208\n",
            "[1000]\tvalidation_0-rmse:0.94651\n",
            "[1200]\tvalidation_0-rmse:0.94223\n",
            "[1400]\tvalidation_0-rmse:0.93872\n",
            "[1600]\tvalidation_0-rmse:0.93560\n",
            "[1666]\tvalidation_0-rmse:0.93441\n",
            "\n",
            "--- Model 6 (50% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00811\n",
            "[200]\tvalidation_0-rmse:0.98649\n",
            "[400]\tvalidation_0-rmse:0.97518\n",
            "[600]\tvalidation_0-rmse:0.96740\n",
            "[800]\tvalidation_0-rmse:0.96173\n",
            "[1000]\tvalidation_0-rmse:0.95701\n",
            "[1200]\tvalidation_0-rmse:0.95347\n",
            "[1400]\tvalidation_0-rmse:0.95032\n",
            "[1600]\tvalidation_0-rmse:0.94771\n",
            "[1666]\tvalidation_0-rmse:0.94704\n",
            "\n",
            "--- Model 7 (40% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00845\n",
            "[200]\tvalidation_0-rmse:0.98769\n",
            "[400]\tvalidation_0-rmse:0.97786\n",
            "[600]\tvalidation_0-rmse:0.97089\n",
            "[800]\tvalidation_0-rmse:0.96640\n",
            "[1000]\tvalidation_0-rmse:0.96302\n",
            "[1200]\tvalidation_0-rmse:0.96002\n",
            "[1400]\tvalidation_0-rmse:0.95772\n",
            "[1600]\tvalidation_0-rmse:0.95585\n",
            "[1666]\tvalidation_0-rmse:0.95529\n",
            "\n",
            "##################################################\n",
            "### Fold 4\n",
            "##################################################\n",
            "\n",
            "--- Model 1 (100% Full Data) ---\n",
            "[0]\tvalidation_0-rmse:1.01672\n",
            "[200]\tvalidation_0-rmse:0.98910\n",
            "[400]\tvalidation_0-rmse:0.97265\n",
            "[600]\tvalidation_0-rmse:0.96043\n",
            "[800]\tvalidation_0-rmse:0.94994\n",
            "[1000]\tvalidation_0-rmse:0.94134\n",
            "[1200]\tvalidation_0-rmse:0.93400\n",
            "[1400]\tvalidation_0-rmse:0.92737\n",
            "[1600]\tvalidation_0-rmse:0.92083\n",
            "[1666]\tvalidation_0-rmse:0.91908\n",
            "\n",
            "--- Model 2 (90% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01677\n",
            "[200]\tvalidation_0-rmse:0.99005\n",
            "[400]\tvalidation_0-rmse:0.97403\n",
            "[600]\tvalidation_0-rmse:0.96179\n",
            "[800]\tvalidation_0-rmse:0.95244\n",
            "[1000]\tvalidation_0-rmse:0.94474\n",
            "[1200]\tvalidation_0-rmse:0.93815\n",
            "[1400]\tvalidation_0-rmse:0.93248\n",
            "[1600]\tvalidation_0-rmse:0.92740\n",
            "[1666]\tvalidation_0-rmse:0.92578\n",
            "\n",
            "--- Model 3 (80% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01671\n",
            "[200]\tvalidation_0-rmse:0.99025\n",
            "[400]\tvalidation_0-rmse:0.97452\n",
            "[600]\tvalidation_0-rmse:0.96363\n",
            "[800]\tvalidation_0-rmse:0.95454\n",
            "[1000]\tvalidation_0-rmse:0.94740\n",
            "[1200]\tvalidation_0-rmse:0.94170\n",
            "[1400]\tvalidation_0-rmse:0.93630\n",
            "[1600]\tvalidation_0-rmse:0.93172\n",
            "[1666]\tvalidation_0-rmse:0.93054\n",
            "\n",
            "--- Model 4 (70% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01687\n",
            "[200]\tvalidation_0-rmse:0.99008\n",
            "[400]\tvalidation_0-rmse:0.97565\n",
            "[600]\tvalidation_0-rmse:0.96577\n",
            "[800]\tvalidation_0-rmse:0.95730\n",
            "[1000]\tvalidation_0-rmse:0.95070\n",
            "[1200]\tvalidation_0-rmse:0.94494\n",
            "[1400]\tvalidation_0-rmse:0.93992\n",
            "[1600]\tvalidation_0-rmse:0.93560\n",
            "[1666]\tvalidation_0-rmse:0.93446\n",
            "\n",
            "--- Model 5 (60% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01683\n",
            "[200]\tvalidation_0-rmse:0.99179\n",
            "[400]\tvalidation_0-rmse:0.97824\n",
            "[600]\tvalidation_0-rmse:0.96940\n",
            "[800]\tvalidation_0-rmse:0.96178\n",
            "[1000]\tvalidation_0-rmse:0.95631\n",
            "[1200]\tvalidation_0-rmse:0.95183\n",
            "[1400]\tvalidation_0-rmse:0.94794\n",
            "[1600]\tvalidation_0-rmse:0.94410\n",
            "[1666]\tvalidation_0-rmse:0.94314\n",
            "\n",
            "--- Model 6 (50% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01734\n",
            "[200]\tvalidation_0-rmse:0.99540\n",
            "[400]\tvalidation_0-rmse:0.98429\n",
            "[600]\tvalidation_0-rmse:0.97588\n",
            "[800]\tvalidation_0-rmse:0.97018\n",
            "[1000]\tvalidation_0-rmse:0.96542\n",
            "[1200]\tvalidation_0-rmse:0.96195\n",
            "[1400]\tvalidation_0-rmse:0.95899\n",
            "[1600]\tvalidation_0-rmse:0.95663\n",
            "[1666]\tvalidation_0-rmse:0.95575\n",
            "\n",
            "--- Model 7 (40% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.01778\n",
            "[200]\tvalidation_0-rmse:0.99590\n",
            "[400]\tvalidation_0-rmse:0.98569\n",
            "[600]\tvalidation_0-rmse:0.97917\n",
            "[800]\tvalidation_0-rmse:0.97439\n",
            "[1000]\tvalidation_0-rmse:0.97107\n",
            "[1200]\tvalidation_0-rmse:0.96814\n",
            "[1400]\tvalidation_0-rmse:0.96620\n",
            "[1600]\tvalidation_0-rmse:0.96438\n",
            "[1666]\tvalidation_0-rmse:0.96401\n",
            "\n",
            "##################################################\n",
            "### Fold 5\n",
            "##################################################\n",
            "\n",
            "--- Model 1 (100% Full Data) ---\n",
            "[0]\tvalidation_0-rmse:1.00033\n",
            "[200]\tvalidation_0-rmse:0.97346\n",
            "[400]\tvalidation_0-rmse:0.95779\n",
            "[600]\tvalidation_0-rmse:0.94572\n",
            "[800]\tvalidation_0-rmse:0.93586\n",
            "[1000]\tvalidation_0-rmse:0.92733\n",
            "[1200]\tvalidation_0-rmse:0.92011\n",
            "[1400]\tvalidation_0-rmse:0.91342\n",
            "[1600]\tvalidation_0-rmse:0.90785\n",
            "[1666]\tvalidation_0-rmse:0.90579\n",
            "\n",
            "--- Model 2 (90% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00030\n",
            "[200]\tvalidation_0-rmse:0.97387\n",
            "[400]\tvalidation_0-rmse:0.95856\n",
            "[600]\tvalidation_0-rmse:0.94683\n",
            "[800]\tvalidation_0-rmse:0.93776\n",
            "[1000]\tvalidation_0-rmse:0.92987\n",
            "[1200]\tvalidation_0-rmse:0.92312\n",
            "[1400]\tvalidation_0-rmse:0.91756\n",
            "[1600]\tvalidation_0-rmse:0.91232\n",
            "[1666]\tvalidation_0-rmse:0.91055\n",
            "\n",
            "--- Model 3 (80% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00038\n",
            "[200]\tvalidation_0-rmse:0.97471\n",
            "[400]\tvalidation_0-rmse:0.95966\n",
            "[600]\tvalidation_0-rmse:0.94894\n",
            "[800]\tvalidation_0-rmse:0.93989\n",
            "[1000]\tvalidation_0-rmse:0.93296\n",
            "[1200]\tvalidation_0-rmse:0.92728\n",
            "[1400]\tvalidation_0-rmse:0.92199\n",
            "[1600]\tvalidation_0-rmse:0.91731\n",
            "[1666]\tvalidation_0-rmse:0.91597\n",
            "\n",
            "--- Model 4 (70% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00040\n",
            "[200]\tvalidation_0-rmse:0.97522\n",
            "[400]\tvalidation_0-rmse:0.96047\n",
            "[600]\tvalidation_0-rmse:0.95021\n",
            "[800]\tvalidation_0-rmse:0.94278\n",
            "[1000]\tvalidation_0-rmse:0.93679\n",
            "[1200]\tvalidation_0-rmse:0.93167\n",
            "[1400]\tvalidation_0-rmse:0.92708\n",
            "[1600]\tvalidation_0-rmse:0.92292\n",
            "[1666]\tvalidation_0-rmse:0.92160\n",
            "\n",
            "--- Model 5 (60% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00050\n",
            "[200]\tvalidation_0-rmse:0.97615\n",
            "[400]\tvalidation_0-rmse:0.96310\n",
            "[600]\tvalidation_0-rmse:0.95397\n",
            "[800]\tvalidation_0-rmse:0.94686\n",
            "[1000]\tvalidation_0-rmse:0.94193\n",
            "[1200]\tvalidation_0-rmse:0.93707\n",
            "[1400]\tvalidation_0-rmse:0.93332\n",
            "[1600]\tvalidation_0-rmse:0.93031\n",
            "[1666]\tvalidation_0-rmse:0.92913\n",
            "\n",
            "--- Model 6 (50% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00098\n",
            "[200]\tvalidation_0-rmse:0.97816\n",
            "[400]\tvalidation_0-rmse:0.96700\n",
            "[600]\tvalidation_0-rmse:0.95963\n",
            "[800]\tvalidation_0-rmse:0.95379\n",
            "[1000]\tvalidation_0-rmse:0.94931\n",
            "[1200]\tvalidation_0-rmse:0.94530\n",
            "[1400]\tvalidation_0-rmse:0.94243\n",
            "[1600]\tvalidation_0-rmse:0.93956\n",
            "[1666]\tvalidation_0-rmse:0.93878\n",
            "\n",
            "--- Model 7 (40% Recent) ---\n",
            "[0]\tvalidation_0-rmse:1.00147\n",
            "[200]\tvalidation_0-rmse:0.98084\n",
            "[400]\tvalidation_0-rmse:0.97128\n",
            "[600]\tvalidation_0-rmse:0.96504\n",
            "[800]\tvalidation_0-rmse:0.96018\n",
            "[1000]\tvalidation_0-rmse:0.95658\n",
            "[1200]\tvalidation_0-rmse:0.95397\n",
            "[1400]\tvalidation_0-rmse:0.95203\n",
            "[1600]\tvalidation_0-rmse:0.95003\n",
            "[1666]\tvalidation_0-rmse:0.94961\n",
            "\n",
            "==================================================\n",
            "INDIVIDUAL MODEL PERFORMANCE (+X174)\n",
            "==================================================\n",
            "Model 1 (100% Full Data) Pearson Correlation: 0.4783\n",
            "Model 2 (90% Recent) Pearson Correlation: 0.4908\n",
            "Model 3 (80% Recent) Pearson Correlation: 0.4964\n",
            "Model 4 (70% Recent) Pearson Correlation: 0.5027\n",
            "Model 5 (60% Recent) Pearson Correlation: 0.5098\n",
            "Model 6 (50% Recent) Pearson Correlation: 0.5126\n",
            "Model 7 (40% Recent) Pearson Correlation: 0.5123\n",
            "\n",
            "Ensemble (Equal Weight) Pearson Correlation: 0.5097\n",
            "Weighted Ensemble Pearson Correlation: 0.5100\n",
            "\n",
            "Using weighted ensemble for final predictions\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Competition: DRW Crypto Market Prediction | Date: Week 3 | Purpose: Add Back X174\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def reduce_mem_usage(dataframe, dataset):\n",
        "   print('Reducing memory usage for:', dataset)\n",
        "   initial_mem_usage = dataframe.memory_usage().sum() / 1024**2\n",
        "\n",
        "   for col in dataframe.columns:\n",
        "       col_type = dataframe[col].dtype\n",
        "       c_min = dataframe[col].min()\n",
        "       c_max = dataframe[col].max()\n",
        "\n",
        "       if str(col_type)[:3] == 'int':\n",
        "           if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.int8)\n",
        "           elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.int16)\n",
        "           elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.int32)\n",
        "           elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.int64)\n",
        "       else:\n",
        "           if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.float16)\n",
        "           elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.float32)\n",
        "           else:\n",
        "               dataframe[col] = dataframe[col].astype(np.float64)\n",
        "\n",
        "   final_mem_usage = dataframe.memory_usage().sum() / 1024**2\n",
        "   print('--- Memory usage before: {:.2f} MB'.format(initial_mem_usage))\n",
        "   print('--- Memory usage after: {:.2f} MB'.format(final_mem_usage))\n",
        "   print('--- Decreased memory usage by {:.1f}%\\n'.format(100 * (initial_mem_usage - final_mem_usage) / initial_mem_usage))\n",
        "\n",
        "   return dataframe\n",
        "\n",
        "def create_time_weights(n_samples, decay_factor=0.95):\n",
        "   \"\"\"Create exponentially decaying weights based on sample position.\"\"\"\n",
        "   positions = np.arange(n_samples)\n",
        "   normalized_positions = positions / (n_samples - 1)\n",
        "   weights = decay_factor ** (1 - normalized_positions)\n",
        "   weights = weights * n_samples / weights.sum()\n",
        "   return weights\n",
        "\n",
        "# Load data\n",
        "train = pd.read_parquet(drw_crypto_market_prediction_path + '/train.parquet')\n",
        "test = pd.read_parquet(drw_crypto_market_prediction_path + '/test.parquet')\n",
        "sample_submission = pd.read_csv(drw_crypto_market_prediction_path + '/sample_submission.csv')\n",
        "\n",
        "# Add back X174 (lowest AV importance of removed features)\n",
        "selected_features = [\n",
        "   'X863', 'X856', 'X344', 'X598', 'X862', 'X385', 'X852', 'X603', 'X860',\n",
        "   'X415', 'X345', 'X137', 'X855', 'X178', 'X532', 'X168', 'X174',\n",
        "   'bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume'\n",
        "]\n",
        "\n",
        "train = train[selected_features + [\"label\"]]\n",
        "test = test[selected_features]\n",
        "\n",
        "train = reduce_mem_usage(train, \"train\")\n",
        "test = reduce_mem_usage(test, \"test\")\n",
        "\n",
        "print(\"Train=\", train.shape)\n",
        "print(\"Test=\", test.shape)\n",
        "\n",
        "FEATURES = [c for c in train.columns if c not in [\"label\"]]\n",
        "print(f\"There are {len(FEATURES)} FEATURES (added back X174)\")\n",
        "\n",
        "# Cross-validation\n",
        "FOLDS = 5\n",
        "kf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "# Create bins for stratification\n",
        "train['label_float32'] = train['label'].astype(np.float32)\n",
        "train['label_bins'] = pd.qcut(train['label_float32'], q=10, labels=False, duplicates='drop')\n",
        "train = train.drop('label_float32', axis=1)\n",
        "\n",
        "# XGBoost parameters\n",
        "xgb_params = {\n",
        "   \"tree_method\": \"hist\",\n",
        "   \"device\": \"cuda\",\n",
        "   \"colsample_bylevel\": 0.4778015829774066,\n",
        "   \"colsample_bynode\": 0.362764358742407,\n",
        "   \"colsample_bytree\": 0.7107423488010493,\n",
        "   \"gamma\": 1.7094857725240398,\n",
        "   \"learning_rate\": 0.02213323588455387,\n",
        "   \"max_depth\": 20,\n",
        "   \"max_leaves\": 12,\n",
        "   \"min_child_weight\": 16,\n",
        "   \"n_estimators\": 1667,\n",
        "   \"n_jobs\": -1,\n",
        "   \"random_state\": 42,\n",
        "   \"reg_alpha\": 39.352415706891264,\n",
        "   \"reg_lambda\": 75.44843704068275,\n",
        "   \"subsample\": 0.06566669853471274,\n",
        "   \"verbosity\": 0,\n",
        "   \"objective\": \"reg:squarederror\"\n",
        "}\n",
        "\n",
        "# Define model configurations\n",
        "model_configs = [\n",
        "   {\"name\": \"Model 1 (100% Full Data)\", \"percent\": 1.00},\n",
        "   {\"name\": \"Model 2 (90% Recent)\", \"percent\": 0.90},\n",
        "   {\"name\": \"Model 3 (80% Recent)\", \"percent\": 0.80},\n",
        "   {\"name\": \"Model 4 (70% Recent)\", \"percent\": 0.70},\n",
        "   {\"name\": \"Model 5 (60% Recent)\", \"percent\": 0.60},\n",
        "   {\"name\": \"Model 6 (50% Recent)\", \"percent\": 0.50},\n",
        "   {\"name\": \"Model 7 (40% Recent)\", \"percent\": 0.40}\n",
        "]\n",
        "\n",
        "# Initialize predictions\n",
        "n_models = len(model_configs)\n",
        "oof_preds_all = [np.zeros(len(train)) for _ in range(n_models)]\n",
        "test_preds_all = [np.zeros(len(test)) for _ in range(n_models)]\n",
        "\n",
        "# Generate sample weights for full data\n",
        "sample_weights_full = create_time_weights(len(train), decay_factor=0.95)\n",
        "print(f\"\\nFull data sample weights range: [{sample_weights_full.min():.4f}, {sample_weights_full.max():.4f}]\")\n",
        "\n",
        "# Calculate cutoffs\n",
        "cutoffs = []\n",
        "for config in model_configs:\n",
        "   if config[\"percent\"] == 1.00:\n",
        "       cutoffs.append(0)\n",
        "   else:\n",
        "       cutoff_idx = int(len(train) * (1 - config[\"percent\"]))\n",
        "       cutoffs.append(cutoff_idx)\n",
        "       print(f\"{config['name']} - Using most recent {len(train) - cutoff_idx} samples\")\n",
        "\n",
        "# Cross-validation loop\n",
        "for fold_num, (train_idx, valid_idx) in enumerate(kf.split(train, train['label_bins'])):\n",
        "   print(\"\\n\" + \"#\" * 50)\n",
        "   print(f\"### Fold {fold_num + 1}\")\n",
        "   print(\"#\" * 50)\n",
        "\n",
        "   X_valid = train.iloc[valid_idx][FEATURES]\n",
        "   y_valid = train.iloc[valid_idx][\"label\"]\n",
        "   X_test = test[FEATURES]\n",
        "\n",
        "   # Train each model\n",
        "   for model_idx, (config, cutoff) in enumerate(zip(model_configs, cutoffs)):\n",
        "       print(f\"\\n--- {config['name']} ---\")\n",
        "\n",
        "       if config[\"percent\"] == 1.00:\n",
        "           X_train = train.iloc[train_idx][FEATURES]\n",
        "           y_train = train.iloc[train_idx][\"label\"]\n",
        "           train_weights = sample_weights_full[train_idx]\n",
        "       else:\n",
        "           train_idx_recent = train_idx[train_idx >= cutoff]\n",
        "           train_idx_recent_adjusted = train_idx_recent - cutoff\n",
        "           train_recent = train.iloc[cutoff:].reset_index(drop=True)\n",
        "\n",
        "           X_train = train_recent.iloc[train_idx_recent_adjusted][FEATURES]\n",
        "           y_train = train_recent.iloc[train_idx_recent_adjusted][\"label\"]\n",
        "\n",
        "           sample_weights_recent = create_time_weights(len(train_recent), decay_factor=0.95)\n",
        "           train_weights = sample_weights_recent[train_idx_recent_adjusted]\n",
        "\n",
        "       # Train model\n",
        "       model = xgb.XGBRegressor(**xgb_params, early_stopping_rounds=25)\n",
        "       model.fit(\n",
        "           X_train, y_train,\n",
        "           sample_weight=train_weights,\n",
        "           eval_set=[(X_valid, y_valid)],\n",
        "           verbose=200\n",
        "       )\n",
        "\n",
        "       # Make predictions\n",
        "       if config[\"percent\"] == 1.00:\n",
        "           oof_preds_all[model_idx][valid_idx] = model.predict(X_valid)\n",
        "       else:\n",
        "           valid_idx_in_range = valid_idx[valid_idx >= cutoff]\n",
        "           if len(valid_idx_in_range) > 0:\n",
        "               X_valid_subset = train.iloc[valid_idx_in_range][FEATURES]\n",
        "               oof_preds_all[model_idx][valid_idx_in_range] = model.predict(X_valid_subset)\n",
        "\n",
        "           valid_idx_out_range = valid_idx[valid_idx < cutoff]\n",
        "           if len(valid_idx_out_range) > 0:\n",
        "               oof_preds_all[model_idx][valid_idx_out_range] = oof_preds_all[0][valid_idx_out_range]\n",
        "\n",
        "       test_preds_all[model_idx] += model.predict(X_test)\n",
        "\n",
        "# Average test predictions across folds\n",
        "for i in range(n_models):\n",
        "   test_preds_all[i] /= FOLDS\n",
        "\n",
        "# Calculate individual model scores\n",
        "pearson_scores = []\n",
        "for i, config in enumerate(model_configs):\n",
        "   score = pearsonr(train[\"label\"], oof_preds_all[i])[0]\n",
        "   pearson_scores.append(score)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"INDIVIDUAL MODEL PERFORMANCE (+X174)\")\n",
        "print(\"=\" * 50)\n",
        "for config, score in zip(model_configs, pearson_scores):\n",
        "   print(f\"{config['name']} Pearson Correlation: {score:.4f}\")\n",
        "\n",
        "# Create ensemble predictions\n",
        "ensemble_oof_preds = np.mean(oof_preds_all, axis=0)\n",
        "ensemble_test_preds = np.mean(test_preds_all, axis=0)\n",
        "\n",
        "ensemble_pearson_score = pearsonr(train[\"label\"], ensemble_oof_preds)[0]\n",
        "print(f\"\\nEnsemble (Equal Weight) Pearson Correlation: {ensemble_pearson_score:.4f}\")\n",
        "\n",
        "# Weighted ensemble\n",
        "total_score = sum(pearson_scores)\n",
        "weights = [score / total_score for score in pearson_scores]\n",
        "\n",
        "weighted_ensemble_oof = np.zeros(len(train))\n",
        "weighted_ensemble_test = np.zeros(len(test))\n",
        "\n",
        "for i in range(n_models):\n",
        "   weighted_ensemble_oof += weights[i] * oof_preds_all[i]\n",
        "   weighted_ensemble_test += weights[i] * test_preds_all[i]\n",
        "\n",
        "weighted_ensemble_score = pearsonr(train[\"label\"], weighted_ensemble_oof)[0]\n",
        "print(f\"Weighted Ensemble Pearson Correlation: {weighted_ensemble_score:.4f}\")\n",
        "\n",
        "# Use the better ensemble\n",
        "if weighted_ensemble_score > ensemble_pearson_score:\n",
        "   final_test_preds = weighted_ensemble_test\n",
        "   print(\"\\nUsing weighted ensemble for final predictions\")\n",
        "else:\n",
        "   final_test_preds = ensemble_test_preds\n",
        "   print(\"\\nUsing simple average ensemble for final predictions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Submission saved to submission_with_X174.csv!\n",
            "\n",
            "=== GAP-FIRST VALIDATION ===\n",
            "Ensemble Pearson: 0.5100\n",
            "Model RMSE Std: 0.004741\n",
            "Features: 22 (added back X174)\n",
            "✅ SUBMIT: High correlation and stable models\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Save predictions\n",
        "sample_sub = pd.read_csv('/Users/mahta/Projects/Time-Series-Library/data/drw-crypto-market-prediction/sample_submission.csv')\n",
        "submission = pd.DataFrame({\n",
        "   sample_sub.columns[0]: sample_sub.iloc[:, 0],\n",
        "   'prediction': final_test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_with_X174.csv\", index=False)\n",
        "print(\"\\nSubmission saved to submission_with_X174.csv!\")\n",
        "\n",
        "# Gap-first validation\n",
        "cv_scores = [np.sqrt(np.mean((train[\"label\"] - oof_preds_all[i])**2)) for i in range(n_models)]\n",
        "cv_mean = np.mean(cv_scores)\n",
        "cv_std = np.std(cv_scores)\n",
        "\n",
        "print(f\"\\n=== GAP-FIRST VALIDATION ===\")\n",
        "print(f\"Ensemble Pearson: {weighted_ensemble_score:.4f}\")\n",
        "print(f\"Model RMSE Std: {cv_std:.6f}\")\n",
        "print(f\"Features: {len(FEATURES)} (added back X174)\")\n",
        "\n",
        "if cv_std < 0.01 and weighted_ensemble_score > 0.4:\n",
        "   print(\"✅ SUBMIT: High correlation and stable models\")\n",
        "else:\n",
        "   print(\"⚠️  CAUTION: Review before submission\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Timeseries Time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Import error: No module named 'sktime.datasets'\n",
            "Some functionality may be limited, but we'll continue with available components.\n",
            "✅ Time-Series Library setup complete!\n",
            "Available models for benchmarking...\n",
            "Models to benchmark: ['Transformer', 'Informer', 'Autoformer', 'FEDformer', 'TimesNet', 'PatchTST', 'iTransformer', 'Mamba', 'TimeMixer', 'TSMixer', 'Crossformer', 'ETSformer']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Time-Series Transformer Benchmark for Crypto Prediction\n",
        "Let's prepare the data and benchmark multiple transformer models from the library\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "from types import SimpleNamespace\n",
        "import warnings\n",
        "import time\n",
        "import gc\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import the Time-Series-Library modules\n",
        "sys.path.append('/Users/mahta/Projects/Time-Series-Library')\n",
        "\n",
        "# Try to import the required modules with error handling\n",
        "try:\n",
        "    from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
        "    from utils.metrics import metric\n",
        "    from utils.tools import EarlyStopping, adjust_learning_rate\n",
        "    print(\"✅ Time-Series-Library modules imported successfully!\")\n",
        "except ImportError as e:\n",
        "    print(f\"⚠️ Import error: {e}\")\n",
        "    print(\"Some functionality may be limited, but we'll continue with available components.\")\n",
        "\n",
        "# Create a custom dataset class for our crypto data\n",
        "class CryptoDataset(Dataset):\n",
        "    def __init__(self, data, seq_len=96, label_len=48, pred_len=24):\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "        self.label_len = label_len  \n",
        "        self.pred_len = pred_len\n",
        "        \n",
        "        # Prepare features (everything except label)\n",
        "        self.features = [col for col in data.columns if col != 'label']\n",
        "        self.data_x = data[self.features].values\n",
        "        self.data_y = data['label'].values.reshape(-1, 1)\n",
        "        \n",
        "        # Normalize the data\n",
        "        self.data_x = (self.data_x - self.data_x.mean(axis=0)) / (self.data_x.std(axis=0) + 1e-8)\n",
        "        self.data_y = (self.data_y - self.data_y.mean()) / (self.data_y.std() + 1e-8)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "        \n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        \n",
        "        # Create dummy time marks (zeros for now)\n",
        "        seq_x_mark = np.zeros((self.seq_len, 1))\n",
        "        seq_y_mark = np.zeros((self.label_len + self.pred_len, 1))\n",
        "        \n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "# Function to create args for different models\n",
        "def create_model_args(model_name, data_info):\n",
        "    args = SimpleNamespace()\n",
        "    \n",
        "    # Basic configuration\n",
        "    args.task_name = 'long_term_forecast'\n",
        "    args.is_training = 1\n",
        "    args.model_id = f'crypto_{model_name}'\n",
        "    args.model = model_name\n",
        "    \n",
        "    # Data configuration\n",
        "    args.data = 'custom'\n",
        "    args.features = 'M'  # Multivariate\n",
        "    args.target = 'label'\n",
        "    args.freq = 't'  # minutely\n",
        "    args.checkpoints = './checkpoints/'\n",
        "    \n",
        "    # Model dimensions\n",
        "    args.seq_len = 96\n",
        "    args.label_len = 48\n",
        "    args.pred_len = 24\n",
        "    args.enc_in = data_info['n_features']\n",
        "    args.dec_in = data_info['n_features'] \n",
        "    args.c_out = 1  # predicting single target\n",
        "    \n",
        "    # Model architecture\n",
        "    args.d_model = 128\n",
        "    args.n_heads = 8\n",
        "    args.e_layers = 2\n",
        "    args.d_layers = 1\n",
        "    args.d_ff = 256\n",
        "    args.dropout = 0.1\n",
        "    args.activation = 'gelu'\n",
        "    args.embed = 'timeF'\n",
        "    args.distil = True\n",
        "    args.factor = 1\n",
        "    args.moving_avg = 25\n",
        "    \n",
        "    # Training configuration\n",
        "    args.batch_size = 64\n",
        "    args.learning_rate = 0.0001\n",
        "    args.train_epochs = 10\n",
        "    args.patience = 3\n",
        "    args.des = f'{model_name}_benchmark'\n",
        "    args.itr = 1\n",
        "    args.loss = 'MSE'\n",
        "    args.lradj = 'type1'\n",
        "    args.use_amp = False\n",
        "    \n",
        "    # Device configuration\n",
        "    args.use_gpu = torch.cuda.is_available()\n",
        "    args.gpu = 0\n",
        "    args.use_multi_gpu = False\n",
        "    args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    # Model-specific parameters\n",
        "    if model_name == 'TimesNet':\n",
        "        args.top_k = 5\n",
        "        args.num_kernels = 6\n",
        "    elif model_name == 'PatchTST':\n",
        "        args.patch_len = 16\n",
        "        args.stride = 8\n",
        "    elif model_name == 'iTransformer':\n",
        "        args.use_norm = 1\n",
        "    elif model_name == 'Mamba':\n",
        "        args.expand = 2\n",
        "        args.d_conv = 4\n",
        "    elif model_name == 'TimeMixer':\n",
        "        args.down_sampling_layers = 3\n",
        "        args.down_sampling_method = 'avg'\n",
        "        args.down_sampling_window = 2\n",
        "    \n",
        "    return args\n",
        "\n",
        "print(\"✅ Time-Series Library setup complete!\")\n",
        "print(\"Available models for benchmarking...\")\n",
        "\n",
        "# List of transformer models to benchmark\n",
        "transformer_models = [\n",
        "    'Transformer', 'Informer', 'Autoformer', 'FEDformer', \n",
        "    'TimesNet', 'PatchTST', 'iTransformer', 'Mamba',\n",
        "    'TimeMixer', 'TSMixer', 'Crossformer', 'ETSformer'\n",
        "]\n",
        "\n",
        "print(f\"Models to benchmark: {transformer_models}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Preparing crypto data for time series modeling...\n",
            "Train data shape: (525887, 896)\n",
            "Test data shape: (538150, 896)\n",
            "Time series splits - Train: 368120, Val: 78883, Test: 78884\n",
            "Data info: {'n_features': 22, 'n_samples_train': 368120, 'n_samples_val': 78883, 'n_samples_test': 78884}\n",
            "Missing values in training data: 0\n",
            "✅ Data preparation complete!\n"
          ]
        }
      ],
      "source": [
        "# Prepare the data for time series forecasting\n",
        "print(\"📊 Preparing crypto data for time series modeling...\")\n",
        "\n",
        "# Load the data\n",
        "train_ts = pd.read_parquet(drw_crypto_market_prediction_path + '/train.parquet')\n",
        "test_ts = pd.read_parquet(drw_crypto_market_prediction_path + '/test.parquet')\n",
        "\n",
        "print(f\"Train data shape: {train_ts.shape}\")\n",
        "print(f\"Test data shape: {test_ts.shape}\")\n",
        "\n",
        "# Use the same features as our XGBoost model\n",
        "selected_features = [\n",
        "    'X863', 'X856', 'X344', 'X598', 'X862', 'X385', 'X852', 'X603', 'X860',\n",
        "    'X415', 'X345', 'X137', 'X855', 'X178', 'X532', 'X168', 'X174',\n",
        "    'bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume'\n",
        "]\n",
        "\n",
        "# Prepare training data\n",
        "train_ts_features = train_ts[selected_features + ['label']].copy()\n",
        "\n",
        "# Create time index (assuming sequential data)\n",
        "train_ts_features = train_ts_features.reset_index(drop=True)\n",
        "\n",
        "# Split into train/val/test for time series (70/15/15 split)\n",
        "n_samples = len(train_ts_features)\n",
        "train_size = int(0.7 * n_samples)\n",
        "val_size = int(0.15 * n_samples)\n",
        "\n",
        "ts_train = train_ts_features[:train_size].copy()\n",
        "ts_val = train_ts_features[train_size:train_size+val_size].copy()\n",
        "ts_test = train_ts_features[train_size+val_size:].copy()\n",
        "\n",
        "print(f\"Time series splits - Train: {len(ts_train)}, Val: {len(ts_val)}, Test: {len(ts_test)}\")\n",
        "\n",
        "# Data info for models\n",
        "data_info = {\n",
        "    'n_features': len(selected_features),\n",
        "    'n_samples_train': len(ts_train),\n",
        "    'n_samples_val': len(ts_val),\n",
        "    'n_samples_test': len(ts_test)\n",
        "}\n",
        "\n",
        "print(f\"Data info: {data_info}\")\n",
        "\n",
        "# Check for any missing values\n",
        "print(f\"Missing values in training data: {ts_train.isnull().sum().sum()}\")\n",
        "if ts_train.isnull().sum().sum() > 0:\n",
        "    print(\"Filling missing values with forward fill...\")\n",
        "    ts_train = ts_train.fillna(method='ffill').fillna(method='bfill')\n",
        "    ts_val = ts_val.fillna(method='ffill').fillna(method='bfill')\n",
        "    ts_test = ts_test.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "print(\"✅ Data preparation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🛠️ Simple transformer benchmark ready!\n"
          ]
        }
      ],
      "source": [
        "# Alternative approach: Simple transformer benchmark using PyTorch directly\n",
        "# This doesn't require the full Time-Series-Library framework\n",
        "\n",
        "class SimpleTransformerModel(nn.Module):\n",
        "    \"\"\"A simple transformer model for time series forecasting\"\"\"\n",
        "    def __init__(self, input_dim, d_model=128, nhead=8, num_layers=2, seq_len=96, pred_len=24):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.d_model = d_model\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "        \n",
        "        # Input projection\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "        \n",
        "        # Positional encoding\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(seq_len, d_model))\n",
        "        \n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, \n",
        "            nhead=nhead, \n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        \n",
        "        # Output projection\n",
        "        self.output_projection = nn.Linear(d_model, 1)\n",
        "        \n",
        "        # Prediction head\n",
        "        self.prediction_head = nn.Linear(seq_len, pred_len)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, input_dim)\n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        # Project input to model dimension\n",
        "        x = self.input_projection(x)  # (batch_size, seq_len, d_model)\n",
        "        \n",
        "        # Add positional encoding\n",
        "        x = x + self.pos_encoding.unsqueeze(0)  # Broadcasting\n",
        "        \n",
        "        # Apply transformer\n",
        "        x = self.transformer(x)  # (batch_size, seq_len, d_model)\n",
        "        \n",
        "        # Project to single output dimension\n",
        "        x = self.output_projection(x)  # (batch_size, seq_len, 1)\n",
        "        x = x.squeeze(-1)  # (batch_size, seq_len)\n",
        "        \n",
        "        # Project to prediction length\n",
        "        predictions = self.prediction_head(x)  # (batch_size, pred_len)\n",
        "        \n",
        "        return predictions.unsqueeze(-1)  # (batch_size, pred_len, 1)\n",
        "\n",
        "def run_simple_transformer_benchmark(train_data, val_data, test_data, data_info):\n",
        "    \"\"\"Run a simple transformer benchmark\"\"\"\n",
        "    print(\"🚀 Running Simple Transformer Benchmark...\")\n",
        "    \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "    \n",
        "    # Prepare data\n",
        "    seq_len, pred_len = 96, 24\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = CryptoDataset(train_data, seq_len=seq_len, pred_len=pred_len)\n",
        "    val_dataset = CryptoDataset(val_data, seq_len=seq_len, pred_len=pred_len)\n",
        "    test_dataset = CryptoDataset(test_data, seq_len=seq_len, pred_len=pred_len)\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
        "    \n",
        "    # Initialize model\n",
        "    model = SimpleTransformerModel(\n",
        "        input_dim=data_info['n_features'],\n",
        "        d_model=128,\n",
        "        nhead=8,\n",
        "        num_layers=2,\n",
        "        seq_len=seq_len,\n",
        "        pred_len=pred_len\n",
        "    ).to(device)\n",
        "    \n",
        "    # Training setup\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    # Training loop\n",
        "    print(\"Training the model...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    model.train()\n",
        "    for epoch in range(5):  # Quick training for benchmark\n",
        "        total_loss = 0\n",
        "        for batch_idx, (batch_x, batch_y, _, _) in enumerate(train_loader):\n",
        "            batch_x = batch_x.float().to(device)\n",
        "            batch_y = batch_y[:, -pred_len:, -1:].float().to(device)  # Last pred_len steps, target feature\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.6f}\")\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "    \n",
        "    # Testing\n",
        "    print(\"Testing the model...\")\n",
        "    test_start = time.time()\n",
        "    \n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y, _, _ in test_loader:\n",
        "            batch_x = batch_x.float().to(device)\n",
        "            batch_y = batch_y[:, -pred_len:, -1:].float()  # Target values\n",
        "            \n",
        "            outputs = model(batch_x).cpu()\n",
        "            \n",
        "            predictions.append(outputs.numpy())\n",
        "            targets.append(batch_y.numpy())\n",
        "    \n",
        "    # Concatenate predictions\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    targets = np.concatenate(targets, axis=0)\n",
        "    \n",
        "    testing_time = time.time() - test_start\n",
        "    \n",
        "    # Calculate metrics\n",
        "    predictions_flat = predictions.flatten()\n",
        "    targets_flat = targets.flatten()\n",
        "    \n",
        "    mse = np.mean((predictions_flat - targets_flat) ** 2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.mean(np.abs(predictions_flat - targets_flat))\n",
        "    \n",
        "    # Calculate correlation\n",
        "    correlation = np.corrcoef(predictions_flat, targets_flat)[0, 1]\n",
        "    \n",
        "    # Model parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    \n",
        "    result = {\n",
        "        'model': 'Simple Transformer',\n",
        "        'mae': mae,\n",
        "        'mse': mse,\n",
        "        'rmse': rmse,\n",
        "        'mape': np.mean(np.abs((targets_flat - predictions_flat) / (targets_flat + 1e-8))) * 100,\n",
        "        'correlation': correlation,\n",
        "        'training_time': training_time,\n",
        "        'testing_time': testing_time,\n",
        "        'total_params': total_params,\n",
        "        'status': 'Success'\n",
        "    }\n",
        "    \n",
        "    print(f\"✅ Simple Transformer completed!\")\n",
        "    print(f\"Correlation: {correlation:.6f}, RMSE: {rmse:.6f}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(\"🛠️ Simple transformer benchmark ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ CustomExp class not available - skipping transformer benchmark\n",
            "🛠️  Custom experiment framework ready!\n",
            "Starting transformer benchmark...\n"
          ]
        }
      ],
      "source": [
        "# Custom experiment class to work with our data\n",
        "# Only define if we successfully imported the base class\n",
        "if 'Exp_Long_Term_Forecast' in globals():\n",
        "    class CustomExp(Exp_Long_Term_Forecast):\n",
        "        def __init__(self, args, train_data, val_data, test_data):\n",
        "            super().__init__(args)\n",
        "            self.train_data = train_data\n",
        "            self.val_data = val_data\n",
        "            self.test_data = test_data\n",
        "            \n",
        "        def _get_data(self, flag):\n",
        "            if flag == 'train':\n",
        "                dataset = CryptoDataset(self.train_data, self.args.seq_len, self.args.label_len, self.args.pred_len)\n",
        "            elif flag == 'val':\n",
        "                dataset = CryptoDataset(self.val_data, self.args.seq_len, self.args.label_len, self.args.pred_len)\n",
        "            else:  # test\n",
        "                dataset = CryptoDataset(self.test_data, self.args.seq_len, self.args.label_len, self.args.pred_len)\n",
        "                \n",
        "            data_loader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=self.args.batch_size,\n",
        "                shuffle=(flag == 'train'),\n",
        "                num_workers=0,\n",
        "                drop_last=True\n",
        "            )\n",
        "            \n",
        "            return dataset, data_loader\n",
        "else:\n",
        "    print(\"⚠️ CustomExp class not available - skipping transformer benchmark\")\n",
        "    CustomExp = None\n",
        "\n",
        "def run_single_model_benchmark(model_name, train_data, val_data, test_data, data_info):\n",
        "    \"\"\"Run benchmark for a single model\"\"\"\n",
        "    print(f\"\\\\n{'='*60}\")\n",
        "    print(f\"🚀 Benchmarking {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Check if required classes are available\n",
        "    if CustomExp is None:\n",
        "        return {\n",
        "            'model': model_name,\n",
        "            'mae': np.nan,\n",
        "            'mse': np.nan,\n",
        "            'rmse': np.nan,\n",
        "            'mape': np.nan,\n",
        "            'correlation': np.nan,\n",
        "            'training_time': np.nan,\n",
        "            'testing_time': np.nan,\n",
        "            'total_params': np.nan,\n",
        "            'status': 'Failed: Time-Series-Library dependencies not available'\n",
        "        }\n",
        "    \n",
        "    try:\n",
        "        # Create model arguments\n",
        "        args = create_model_args(model_name, data_info)\n",
        "        \n",
        "        # Create experiment\n",
        "        exp = CustomExp(args, train_data, val_data, test_data)\n",
        "        \n",
        "        # Create setting name\n",
        "        setting = f'{args.task_name}_{args.model_id}_{args.model}_{args.data}'\n",
        "        \n",
        "        print(f\"⚙️  Training {model_name}...\")\n",
        "        \n",
        "        # Train the model\n",
        "        start_time = time.time()\n",
        "        model = exp.train(setting)\n",
        "        training_time = time.time() - start_time\n",
        "        \n",
        "        print(f\"⏱️  Training completed in {training_time:.2f} seconds\")\n",
        "        \n",
        "        # Test the model\n",
        "        print(f\"🧪 Testing {model_name}...\")\n",
        "        test_start = time.time()\n",
        "        \n",
        "        # Get test predictions\n",
        "        test_data_loader = exp._get_data('test')[1]\n",
        "        preds = []\n",
        "        trues = []\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_data_loader):\n",
        "                batch_x = batch_x.float().to(exp.device)\n",
        "                batch_y = batch_y.float().to(exp.device)\n",
        "                batch_x_mark = batch_x_mark.float().to(exp.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(exp.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(exp.device)\n",
        "                \n",
        "                # prediction\n",
        "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                \n",
        "                # Extract predictions for the target sequence\n",
        "                pred = outputs[:, -args.pred_len:, -1:].detach().cpu().numpy()  # Last feature is target\n",
        "                true = batch_y[:, -args.pred_len:, -1:].detach().cpu().numpy()\n",
        "                \n",
        "                preds.append(pred)\n",
        "                trues.append(true)\n",
        "        \n",
        "        # Concatenate all predictions\n",
        "        preds = np.concatenate(preds, axis=0)\n",
        "        trues = np.concatenate(trues, axis=0)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
        "        \n",
        "        # Calculate correlation (similar to Pearson correlation for our task)\n",
        "        preds_flat = preds.flatten()\n",
        "        trues_flat = trues.flatten()\n",
        "        correlation = np.corrcoef(preds_flat, trues_flat)[0, 1]\n",
        "        \n",
        "        testing_time = time.time() - test_start\n",
        "        \n",
        "        print(f\"✅ {model_name} completed!\")\n",
        "        \n",
        "        return {\n",
        "            'model': model_name,\n",
        "            'mae': mae,\n",
        "            'mse': mse, \n",
        "            'rmse': rmse,\n",
        "            'mape': mape,\n",
        "            'correlation': correlation,\n",
        "            'training_time': training_time,\n",
        "            'testing_time': testing_time,\n",
        "            'total_params': sum(p.numel() for p in model.parameters()),\n",
        "            'status': 'Success'\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error with {model_name}: {str(e)}\")\n",
        "        return {\n",
        "            'model': model_name,\n",
        "            'mae': np.nan,\n",
        "            'mse': np.nan,\n",
        "            'rmse': np.nan, \n",
        "            'mape': np.nan,\n",
        "            'correlation': np.nan,\n",
        "            'training_time': np.nan,\n",
        "            'testing_time': np.nan,\n",
        "            'total_params': np.nan,\n",
        "            'status': f'Failed: {str(e)[:100]}'\n",
        "        }\n",
        "\n",
        "print(\"🛠️  Custom experiment framework ready!\")\n",
        "print(\"Starting transformer benchmark...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 Starting Transformer Benchmark for Crypto Prediction...\n",
            "============================================================\n",
            "🔧 Using Simple PyTorch Transformer approach...\n",
            "🚀 Running Simple Transformer Benchmark...\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Determine which benchmark approach to use\n",
        "benchmark_results = []\n",
        "\n",
        "print(\"🎯 Starting Transformer Benchmark for Crypto Prediction...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Try the Time-Series-Library approach first\n",
        "if CustomExp is not None:\n",
        "    print(\"📚 Using Time-Series-Library framework...\")\n",
        "    \n",
        "    # Run the benchmark on a subset of models first (to avoid long runtime)\n",
        "    priority_models = [\n",
        "        'Transformer',      # Classic transformer\n",
        "        'Autoformer',       # Popular for time series\n",
        "        'Informer',         # Popular for long sequences  \n",
        "        'DLinear',          # Simple but effective\n",
        "        'PatchTST',         # State-of-the-art for many tasks\n",
        "        'iTransformer',     # Recent improvement\n",
        "        'TimesNet'          # Good general purpose model\n",
        "    ]\n",
        "\n",
        "    print(f\"Models to test: {priority_models}\")\n",
        "\n",
        "    # Run benchmark for each model\n",
        "    for i, model_name in enumerate(priority_models):\n",
        "        print(f\"\\\\n[{i+1}/{len(priority_models)}] Processing {model_name}...\")\n",
        "        \n",
        "        # Run the benchmark\n",
        "        result = run_single_model_benchmark(\n",
        "            model_name, \n",
        "            ts_train, \n",
        "            ts_val, \n",
        "            ts_test, \n",
        "            data_info\n",
        "        )\n",
        "        \n",
        "        benchmark_results.append(result)\n",
        "        \n",
        "        # Clean up memory\n",
        "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "        gc.collect()\n",
        "        \n",
        "        print(f\"Result: {result['status']}\")\n",
        "        if result['status'] == 'Success':\n",
        "            print(f\"Correlation: {result['correlation']:.4f}, RMSE: {result['rmse']:.6f}\")\n",
        "\n",
        "else:\n",
        "    print(\"🔧 Using Simple PyTorch Transformer approach...\")\n",
        "    \n",
        "    # Run the simple transformer benchmark\n",
        "    result = run_simple_transformer_benchmark(ts_train, ts_val, ts_test, data_info)\n",
        "    benchmark_results.append(result)\n",
        "    \n",
        "    # Also add a simple baseline for comparison\n",
        "    print(\"\\\\n🔧 Adding Linear Regression baseline...\")\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "    \n",
        "    # Prepare data for linear regression\n",
        "    def prepare_linear_data(data, seq_len=96, pred_len=24):\n",
        "        features = [col for col in data.columns if col != 'label']\n",
        "        X, y = [], []\n",
        "        \n",
        "        for i in range(len(data) - seq_len - pred_len + 1):\n",
        "            # Use last value of sequence as features\n",
        "            X.append(data[features].iloc[i + seq_len - 1].values)\n",
        "            # Predict next pred_len values average\n",
        "            y.append(data['label'].iloc[i + seq_len:i + seq_len + pred_len].mean())\n",
        "        \n",
        "        return np.array(X), np.array(y)\n",
        "    \n",
        "    X_train, y_train = prepare_linear_data(ts_train)\n",
        "    X_test, y_test = prepare_linear_data(ts_test)\n",
        "    \n",
        "    # Train linear regression\n",
        "    start_time = time.time()\n",
        "    lr_model = LinearRegression()\n",
        "    lr_model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    # Test\n",
        "    test_start = time.time()\n",
        "    y_pred = lr_model.predict(X_test)\n",
        "    testing_time = time.time() - test_start\n",
        "    \n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    correlation = np.corrcoef(y_test, y_pred)[0, 1]\n",
        "    \n",
        "    lr_result = {\n",
        "        'model': 'Linear Regression Baseline',\n",
        "        'mae': mae,\n",
        "        'mse': mse,\n",
        "        'rmse': np.sqrt(mse),\n",
        "        'mape': np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100,\n",
        "        'correlation': correlation,\n",
        "        'training_time': training_time,\n",
        "        'testing_time': testing_time,\n",
        "        'total_params': X_train.shape[1],  # Number of features\n",
        "        'status': 'Success'\n",
        "    }\n",
        "    \n",
        "    benchmark_results.append(lr_result)\n",
        "    print(f\"Linear Regression - Correlation: {correlation:.6f}, RMSE: {np.sqrt(mse):.6f}\")\n",
        "\n",
        "print(f\"\\\\n🏁 Benchmark completed! Processed {len(benchmark_results)} models.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive benchmark results table\n",
        "print(\"📊 Creating Transformer Benchmark Results Table...\")\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(benchmark_results)\n",
        "\n",
        "# Sort by correlation (descending) for successful models\n",
        "successful_results = results_df[results_df['status'] == 'Success'].copy()\n",
        "if len(successful_results) > 0:\n",
        "    successful_results = successful_results.sort_values('correlation', ascending=False)\n",
        "\n",
        "# Format the results table\n",
        "def format_results_table(df):\n",
        "    \"\"\"Format the results table for better display\"\"\"\n",
        "    formatted_df = df.copy()\n",
        "    \n",
        "    # Round numerical columns\n",
        "    numeric_cols = ['mae', 'mse', 'rmse', 'mape', 'correlation', 'training_time', 'testing_time']\n",
        "    for col in numeric_cols:\n",
        "        if col in formatted_df.columns:\n",
        "            formatted_df[col] = formatted_df[col].round(6)\n",
        "    \n",
        "    # Format parameter count\n",
        "    if 'total_params' in formatted_df.columns:\n",
        "        formatted_df['total_params'] = formatted_df['total_params'].apply(\n",
        "            lambda x: f\"{x:,}\" if not pd.isna(x) else \"N/A\"\n",
        "        )\n",
        "    \n",
        "    return formatted_df\n",
        "\n",
        "# Display results\n",
        "print(\"\\\\n\" + \"=\"*100)\n",
        "print(\"🏆 TRANSFORMER MODEL BENCHMARK RESULTS - CRYPTO MARKET PREDICTION\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "if len(successful_results) > 0:\n",
        "    print(\"\\\\n📈 SUCCESSFUL MODELS (Ranked by Correlation):\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    formatted_successful = format_results_table(successful_results)\n",
        "    \n",
        "    # Select key columns for display\n",
        "    display_cols = ['model', 'correlation', 'rmse', 'mae', 'training_time', 'total_params']\n",
        "    available_cols = [col for col in display_cols if col in formatted_successful.columns]\n",
        "    \n",
        "    print(formatted_successful[available_cols].to_string(index=False))\n",
        "    \n",
        "    # Highlight best model\n",
        "    best_model = formatted_successful.iloc[0]\n",
        "    print(f\"\\\\n🥇 BEST MODEL: {best_model['model']}\")\n",
        "    print(f\"   Correlation: {best_model['correlation']:.6f}\")\n",
        "    print(f\"   RMSE: {best_model['rmse']:.6f}\")\n",
        "    print(f\"   Training Time: {best_model['training_time']:.2f}s\")\n",
        "\n",
        "# Show failed models if any\n",
        "failed_results = results_df[results_df['status'] != 'Success']\n",
        "if len(failed_results) > 0:\n",
        "    print(f\"\\\\n❌ FAILED MODELS ({len(failed_results)}):\")\n",
        "    print(\"-\" * 40)\n",
        "    for _, row in failed_results.iterrows():\n",
        "        print(f\"   {row['model']}: {row['status']}\")\n",
        "\n",
        "# Compare with XGBoost baseline\n",
        "print(f\"\\\\n📊 COMPARISON WITH XGBOOST BASELINE:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"XGBoost Ensemble Correlation: {weighted_ensemble_score:.6f}\")\n",
        "\n",
        "if len(successful_results) > 0:\n",
        "    best_transformer_corr = successful_results.iloc[0]['correlation']\n",
        "    print(f\"Best Transformer Correlation: {best_transformer_corr:.6f}\")\n",
        "    \n",
        "    improvement = best_transformer_corr - weighted_ensemble_score\n",
        "    print(f\"Improvement: {improvement:+.6f} ({improvement/weighted_ensemble_score*100:+.2f}%)\")\n",
        "    \n",
        "    if improvement > 0:\n",
        "        print(\"✅ Transformers outperformed XGBoost!\")\n",
        "    else:\n",
        "        print(\"⚠️  XGBoost still leads, but transformers are competitive\")\n",
        "        \n",
        "# Model complexity analysis\n",
        "print(f\"\\\\n🔧 MODEL COMPLEXITY ANALYSIS:\")\n",
        "print(\"-\" * 40)\n",
        "if len(successful_results) > 0:\n",
        "    for _, row in successful_results.iterrows():\n",
        "        efficiency_score = row['correlation'] / (row['training_time'] / 60)  # correlation per minute\n",
        "        print(f\"{row['model']:15s} | {row['total_params']:>10s} params | {efficiency_score:.4f} corr/min\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\"*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save benchmark results and create visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Save detailed results to CSV\n",
        "results_df.to_csv('transformer_benchmark_results.csv', index=False)\n",
        "print(\"💾 Benchmark results saved to 'transformer_benchmark_results.csv'\")\n",
        "\n",
        "# Create summary visualization if we have successful results\n",
        "if len(successful_results) > 0:\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    # 1. Correlation comparison\n",
        "    plt.subplot(2, 3, 1)\n",
        "    models = successful_results['model'].tolist()\n",
        "    correlations = successful_results['correlation'].tolist()\n",
        "    \n",
        "    bars = plt.bar(range(len(models)), correlations, alpha=0.7, color='skyblue')\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Correlation')\n",
        "    plt.title('Model Correlation Comparison')\n",
        "    plt.xticks(range(len(models)), models, rotation=45)\n",
        "    \n",
        "    # Add XGBoost baseline line\n",
        "    plt.axhline(y=weighted_ensemble_score, color='red', linestyle='--', \n",
        "                label=f'XGBoost Baseline ({weighted_ensemble_score:.4f})')\n",
        "    plt.legend()\n",
        "    \n",
        "    # Highlight best model\n",
        "    best_idx = 0\n",
        "    bars[best_idx].set_color('gold')\n",
        "    bars[best_idx].set_alpha(1.0)\n",
        "    \n",
        "    # 2. Training time comparison  \n",
        "    plt.subplot(2, 3, 2)\n",
        "    training_times = successful_results['training_time'].tolist()\n",
        "    plt.bar(range(len(models)), training_times, alpha=0.7, color='lightcoral')\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Training Time (seconds)')\n",
        "    plt.title('Training Time Comparison')\n",
        "    plt.xticks(range(len(models)), models, rotation=45)\n",
        "    \n",
        "    # 3. RMSE comparison\n",
        "    plt.subplot(2, 3, 3)\n",
        "    rmse_values = successful_results['rmse'].tolist()\n",
        "    plt.bar(range(len(models)), rmse_values, alpha=0.7, color='lightgreen')\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title('RMSE Comparison (Lower is Better)')\n",
        "    plt.xticks(range(len(models)), models, rotation=45)\n",
        "    \n",
        "    # 4. Model parameters vs Performance\n",
        "    plt.subplot(2, 3, 4)\n",
        "    params = [int(str(p).replace(',', '')) if isinstance(p, str) else p for p in successful_results['total_params']]\n",
        "    plt.scatter(params, correlations, alpha=0.7, s=100, color='purple')\n",
        "    plt.xlabel('Total Parameters')\n",
        "    plt.ylabel('Correlation')\n",
        "    plt.title('Model Size vs Performance')\n",
        "    \n",
        "    # Add model labels\n",
        "    for i, model in enumerate(models):\n",
        "        plt.annotate(model, (params[i], correlations[i]), \n",
        "                    xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "    \n",
        "    # 5. Efficiency Analysis (Correlation per minute)\n",
        "    plt.subplot(2, 3, 5)\n",
        "    efficiency_scores = [corr / (time/60) for corr, time in zip(correlations, training_times)]\n",
        "    bars = plt.bar(range(len(models)), efficiency_scores, alpha=0.7, color='orange')\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Correlation per Minute')\n",
        "    plt.title('Training Efficiency')\n",
        "    plt.xticks(range(len(models)), models, rotation=45)\n",
        "    \n",
        "    # Highlight most efficient\n",
        "    most_efficient_idx = efficiency_scores.index(max(efficiency_scores))\n",
        "    bars[most_efficient_idx].set_color('darkorange')\n",
        "    bars[most_efficient_idx].set_alpha(1.0)\n",
        "    \n",
        "    # 6. Summary radar chart for top 3 models\n",
        "    plt.subplot(2, 3, 6)\n",
        "    top_3_models = successful_results.head(3)\n",
        "    \n",
        "    if len(top_3_models) >= 2:\n",
        "        # Normalize metrics for radar chart\n",
        "        metrics = ['correlation', 'rmse']\n",
        "        normalized_data = []\n",
        "        \n",
        "        for _, model_row in top_3_models.iterrows():\n",
        "            # Normalize correlation (higher is better)\n",
        "            norm_corr = (model_row['correlation'] - successful_results['correlation'].min()) / (successful_results['correlation'].max() - successful_results['correlation'].min())\n",
        "            # Normalize RMSE (lower is better, so invert)\n",
        "            norm_rmse = 1 - (model_row['rmse'] - successful_results['rmse'].min()) / (successful_results['rmse'].max() - successful_results['rmse'].min())\n",
        "            normalized_data.append([norm_corr, norm_rmse])\n",
        "        \n",
        "        x = range(len(metrics))\n",
        "        for i, (_, model_row) in enumerate(top_3_models.iterrows()):\n",
        "            plt.plot(x, normalized_data[i], 'o-', label=model_row['model'], alpha=0.7)\n",
        "        \n",
        "        plt.xlabel('Metrics')\n",
        "        plt.ylabel('Normalized Score')\n",
        "        plt.title('Top 3 Models Comparison')\n",
        "        plt.xticks(x, ['Correlation↑', 'RMSE↓'])\n",
        "        plt.legend()\n",
        "        plt.ylim(0, 1)\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'Need at least 2 successful models\\\\nfor comparison', \n",
        "                ha='center', va='center', transform=plt.gca().transAxes)\n",
        "        plt.title('Model Comparison')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('transformer_benchmark_visualization.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"📈 Visualization saved as 'transformer_benchmark_visualization.png'\")\n",
        "\n",
        "# Create final summary report\n",
        "print(\"\\\\n\" + \"=\"*80)\n",
        "print(\"📋 FINAL BENCHMARK SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "successful_count = len(successful_results)\n",
        "total_count = len(results_df)\n",
        "\n",
        "print(f\"🎯 Models tested: {total_count}\")\n",
        "print(f\"✅ Successful: {successful_count}\")\n",
        "print(f\"❌ Failed: {total_count - successful_count}\")\n",
        "\n",
        "if successful_count > 0:\n",
        "    print(f\"\\\\n🏆 Best performing model: {successful_results.iloc[0]['model']}\")\n",
        "    print(f\"📊 Highest correlation: {successful_results.iloc[0]['correlation']:.6f}\")\n",
        "    \n",
        "    # Find most efficient model\n",
        "    if len(successful_results) > 1:\n",
        "        efficiency_scores = successful_results['correlation'] / (successful_results['training_time'] / 60)\n",
        "        most_efficient_idx = efficiency_scores.idxmax()\n",
        "        most_efficient_model = successful_results.loc[most_efficient_idx, 'model']\n",
        "        print(f\"⚡ Most efficient model: {most_efficient_model}\")\n",
        "        \n",
        "    print(f\"\\\\n💡 Key insights:\")\n",
        "    print(f\"   - Average correlation: {successful_results['correlation'].mean():.4f}\")\n",
        "    print(f\"   - Average training time: {successful_results['training_time'].mean():.1f}s\")\n",
        "    print(f\"   - XGBoost baseline: {weighted_ensemble_score:.4f}\")\n",
        "    \n",
        "    # Recommendation\n",
        "    best_corr = successful_results.iloc[0]['correlation']\n",
        "    if best_corr > weighted_ensemble_score:\n",
        "        print(f\"\\\\n🚀 RECOMMENDATION: Use {successful_results.iloc[0]['model']} for improved performance!\")\n",
        "    else:\n",
        "        print(f\"\\\\n💭 RECOMMENDATION: Consider ensemble of transformers + XGBoost for best results\")\n",
        "\n",
        "print(\"\\\\n🎉 Transformer benchmark completed successfully!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "20250531_DRW",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 11418275,
          "sourceId": 96164,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e23729589a149b8bbac5abbaf20bd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0f100293ac544c3e8615e189a4bb8e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "138bfa59102f46deb0686bd14fc7e5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed7260bc8da9460f86f278d4928dd679",
            "placeholder": "​",
            "style": "IPY_MODEL_8b0776cbba2e473380bfb98c15a48c0d",
            "value": "You don't have permission to access resource at URL: https://www.kaggle.com/api/v1/hello. The server reported the following issues: Unauthenticated"
          }
        },
        "2d35bccaaaa24a71909163dd2017593d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3828e5a9457d4b808609d568b6aad74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38feef5be5604414a6c53a7955187953": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f90efa390f947df87fa3e976569a9e6",
            "placeholder": "​",
            "style": "IPY_MODEL_71c9c27a40da4c6ab8ca86f460e84e5d",
            "value": "Connecting..."
          }
        },
        "3fe743c840564e3db58ca640457c6d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a82705d75f4f9aa7822d814285dbb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68872a6012264841a99b87bc27ef3cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b8b5bab9e4943ebb1c1dda0209ed11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e6679524c3c498e9f8138993d72384e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41a82705d75f4f9aa7822d814285dbb0",
            "placeholder": "​",
            "style": "IPY_MODEL_d1b2a12b402e412f8ddf62db5c111119",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "71c9c27a40da4c6ab8ca86f460e84e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a8b316e2d7b4871908a75ef41c50657": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8570b29c6c6a48f8872978e6c87833f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6e366575d7f466c8f37731859fc34f2",
            "placeholder": "​",
            "style": "IPY_MODEL_2d35bccaaaa24a71909163dd2017593d",
            "value": "401 Client Error."
          }
        },
        "86aa95f469d9461bb79fdd7a5caa7105": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89e5aff0f112449992b3cf3470a4e8f8",
            "placeholder": "​",
            "style": "IPY_MODEL_6b8b5bab9e4943ebb1c1dda0209ed11b",
            "value": "Please make sure you are authenticated if you are trying to access a private resource or a resource requiring consent."
          }
        },
        "89e5aff0f112449992b3cf3470a4e8f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0776cbba2e473380bfb98c15a48c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f90efa390f947df87fa3e976569a9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a532a883232a4de6bb3a93c9542d6ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8570b29c6c6a48f8872978e6c87833f0",
              "IPY_MODEL_138bfa59102f46deb0686bd14fc7e5ed",
              "IPY_MODEL_86aa95f469d9461bb79fdd7a5caa7105"
            ],
            "layout": "IPY_MODEL_dec1fd44a6184e1faa39b606b5bfb073"
          }
        },
        "b34d0672c2ec43ec9c8b4592b0ed93ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_68872a6012264841a99b87bc27ef3cfa",
            "placeholder": "​",
            "style": "IPY_MODEL_c6f59ff4de904947893cdcf6630fe500",
            "value": ""
          }
        },
        "bb274a4efe3b461381af9c86ac03d4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c52cc0e516344b1694e7fdfe87d5c98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb274a4efe3b461381af9c86ac03d4dd",
            "placeholder": "​",
            "style": "IPY_MODEL_3828e5a9457d4b808609d568b6aad74a",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "c6f59ff4de904947893cdcf6630fe500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1b2a12b402e412f8ddf62db5c111119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dec1fd44a6184e1faa39b606b5bfb073": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e34d30b7cf4542e2b8e332cf94b18c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3fe743c840564e3db58ca640457c6d4f",
            "style": "IPY_MODEL_0e23729589a149b8bbac5abbaf20bd73",
            "tooltip": ""
          }
        },
        "e363c6fe27ce4aeb8bacea9613786f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7a8b316e2d7b4871908a75ef41c50657",
            "placeholder": "​",
            "style": "IPY_MODEL_0f100293ac544c3e8615e189a4bb8e00",
            "value": "mahtaao"
          }
        },
        "e6e366575d7f466c8f37731859fc34f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7260bc8da9460f86f278d4928dd679": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
