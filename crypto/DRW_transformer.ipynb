{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "a532a883232a4de6bb3a93c9542d6ac4",
            "6e6679524c3c498e9f8138993d72384e",
            "e363c6fe27ce4aeb8bacea9613786f73",
            "b34d0672c2ec43ec9c8b4592b0ed93ec",
            "e34d30b7cf4542e2b8e332cf94b18c63",
            "c52cc0e516344b1694e7fdfe87d5c98d",
            "dec1fd44a6184e1faa39b606b5bfb073",
            "41a82705d75f4f9aa7822d814285dbb0",
            "d1b2a12b402e412f8ddf62db5c111119",
            "7a8b316e2d7b4871908a75ef41c50657",
            "0f100293ac544c3e8615e189a4bb8e00",
            "68872a6012264841a99b87bc27ef3cfa",
            "c6f59ff4de904947893cdcf6630fe500",
            "3fe743c840564e3db58ca640457c6d4f",
            "0e23729589a149b8bbac5abbaf20bd73",
            "bb274a4efe3b461381af9c86ac03d4dd",
            "3828e5a9457d4b808609d568b6aad74a",
            "38feef5be5604414a6c53a7955187953",
            "9f90efa390f947df87fa3e976569a9e6",
            "71c9c27a40da4c6ab8ca86f460e84e5d",
            "8570b29c6c6a48f8872978e6c87833f0",
            "138bfa59102f46deb0686bd14fc7e5ed",
            "86aa95f469d9461bb79fdd7a5caa7105",
            "e6e366575d7f466c8f37731859fc34f2",
            "2d35bccaaaa24a71909163dd2017593d",
            "ed7260bc8da9460f86f278d4928dd679",
            "8b0776cbba2e473380bfb98c15a48c0d",
            "89e5aff0f112449992b3cf3470a4e8f8",
            "6b8b5bab9e4943ebb1c1dda0209ed11b"
          ]
        },
        "id": "gINwh2vyjMMT",
        "outputId": "5dc6320b-a8da-434f-8df1-239015414767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kaggle credentials set.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "# kagglehub.login()\n",
        "# //read from kaggle.json\n",
        "from kagglehub.config import set_kaggle_credentials\n",
        "\n",
        "import json\n",
        "with open('kaggle.json', 'r') as f:\n",
        "    kaggle_creds = json.load(f)\n",
        "    \n",
        "# kagglehub.login(username=kaggle_creds['username'], key=kaggle_creds['key'])\n",
        "set_kaggle_credentials(username=kaggle_creds['username'], api_key=kaggle_creds['key'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "N_oEzmcxjMMU",
        "outputId": "8f81242b-5a58-415b-c478-c8731d20a24a"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "# drw_crypto_market_prediction_path = kagglehub.competition_download('drw-crypto-market-prediction')\n",
        "\n",
        "# print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "97En93vRjMMU",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'drw_crypto_market_prediction_path' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m    \u001b[38;5;28;01mreturn\u001b[39;00m weights\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m train = pd.read_parquet(\u001b[43mdrw_crypto_market_prediction_path\u001b[49m + \u001b[33m'\u001b[39m\u001b[33m/train.parquet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     52\u001b[39m test = pd.read_parquet(drw_crypto_market_prediction_path + \u001b[33m'\u001b[39m\u001b[33m/test.parquet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     53\u001b[39m sample_submission = pd.read_csv(drw_crypto_market_prediction_path + \u001b[33m'\u001b[39m\u001b[33m/sample_submission.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'drw_crypto_market_prediction_path' is not defined"
          ]
        }
      ],
      "source": [
        "\"\"\"Competition: DRW Crypto Market Prediction | Date: Week 3 | Purpose: Add Back X174\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def reduce_mem_usage(dataframe, dataset):\n",
        "   print('Reducing memory usage for:', dataset)\n",
        "   initial_mem_usage = dataframe.memory_usage().sum() / 1024**2\n",
        "\n",
        "   for col in dataframe.columns:\n",
        "       col_type = dataframe[col].dtype\n",
        "       c_min = dataframe[col].min()\n",
        "       c_max = dataframe[col].max()\n",
        "\n",
        "       if str(col_type)[:3] == 'int':\n",
        "           if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.int8)\n",
        "           elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.int16)\n",
        "           elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.int32)\n",
        "           elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.int64)\n",
        "       else:\n",
        "           if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.float16)\n",
        "           elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "               dataframe[col] = dataframe[col].astype(np.float32)\n",
        "           else:\n",
        "               dataframe[col] = dataframe[col].astype(np.float64)\n",
        "\n",
        "   final_mem_usage = dataframe.memory_usage().sum() / 1024**2\n",
        "   print('--- Memory usage before: {:.2f} MB'.format(initial_mem_usage))\n",
        "   print('--- Memory usage after: {:.2f} MB'.format(final_mem_usage))\n",
        "   print('--- Decreased memory usage by {:.1f}%\\n'.format(100 * (initial_mem_usage - final_mem_usage) / initial_mem_usage))\n",
        "\n",
        "   return dataframe\n",
        "\n",
        "def create_time_weights(n_samples, decay_factor=0.95):\n",
        "   \"\"\"Create exponentially decaying weights based on sample position.\"\"\"\n",
        "   positions = np.arange(n_samples)\n",
        "   normalized_positions = positions / (n_samples - 1)\n",
        "   weights = decay_factor ** (1 - normalized_positions)\n",
        "   weights = weights * n_samples / weights.sum()\n",
        "   return weights\n",
        "\n",
        "# Load data\n",
        "train = pd.read_parquet(drw_crypto_market_prediction_path + '/train.parquet')\n",
        "test = pd.read_parquet(drw_crypto_market_prediction_path + '/test.parquet')\n",
        "sample_submission = pd.read_csv(drw_crypto_market_prediction_path + '/sample_submission.csv')\n",
        "\n",
        "# Add back X174 (lowest AV importance of removed features)\n",
        "selected_features = [\n",
        "   'X863', 'X856', 'X344', 'X598', 'X862', 'X385', 'X852', 'X603', 'X860',\n",
        "   'X415', 'X345', 'X137', 'X855', 'X178', 'X532', 'X168', 'X174',\n",
        "   'bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume'\n",
        "]\n",
        "\n",
        "train = train[selected_features + [\"label\"]]\n",
        "test = test[selected_features]\n",
        "\n",
        "train = reduce_mem_usage(train, \"train\")\n",
        "test = reduce_mem_usage(test, \"test\")\n",
        "\n",
        "print(\"Train=\", train.shape)\n",
        "print(\"Test=\", test.shape)\n",
        "\n",
        "FEATURES = [c for c in train.columns if c not in [\"label\"]]\n",
        "print(f\"There are {len(FEATURES)} FEATURES (added back X174)\")\n",
        "\n",
        "# Cross-validation\n",
        "FOLDS = 5\n",
        "kf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "# Create bins for stratification\n",
        "train['label_float32'] = train['label'].astype(np.float32)\n",
        "train['label_bins'] = pd.qcut(train['label_float32'], q=10, labels=False, duplicates='drop')\n",
        "train = train.drop('label_float32', axis=1)\n",
        "\n",
        "# XGBoost parameters\n",
        "xgb_params = {\n",
        "   \"tree_method\": \"hist\",\n",
        "   \"device\": \"cuda\",\n",
        "   \"colsample_bylevel\": 0.4778015829774066,\n",
        "   \"colsample_bynode\": 0.362764358742407,\n",
        "   \"colsample_bytree\": 0.7107423488010493,\n",
        "   \"gamma\": 1.7094857725240398,\n",
        "   \"learning_rate\": 0.02213323588455387,\n",
        "   \"max_depth\": 20,\n",
        "   \"max_leaves\": 12,\n",
        "   \"min_child_weight\": 16,\n",
        "   \"n_estimators\": 1667,\n",
        "   \"n_jobs\": -1,\n",
        "   \"random_state\": 42,\n",
        "   \"reg_alpha\": 39.352415706891264,\n",
        "   \"reg_lambda\": 75.44843704068275,\n",
        "   \"subsample\": 0.06566669853471274,\n",
        "   \"verbosity\": 0,\n",
        "   \"objective\": \"reg:squarederror\"\n",
        "}\n",
        "\n",
        "# Define model configurations\n",
        "model_configs = [\n",
        "   {\"name\": \"Model 1 (100% Full Data)\", \"percent\": 1.00},\n",
        "   {\"name\": \"Model 2 (90% Recent)\", \"percent\": 0.90},\n",
        "   {\"name\": \"Model 3 (80% Recent)\", \"percent\": 0.80},\n",
        "   {\"name\": \"Model 4 (70% Recent)\", \"percent\": 0.70},\n",
        "   {\"name\": \"Model 5 (60% Recent)\", \"percent\": 0.60},\n",
        "   {\"name\": \"Model 6 (50% Recent)\", \"percent\": 0.50},\n",
        "   {\"name\": \"Model 7 (40% Recent)\", \"percent\": 0.40}\n",
        "]\n",
        "\n",
        "# Initialize predictions\n",
        "n_models = len(model_configs)\n",
        "oof_preds_all = [np.zeros(len(train)) for _ in range(n_models)]\n",
        "test_preds_all = [np.zeros(len(test)) for _ in range(n_models)]\n",
        "\n",
        "# Generate sample weights for full data\n",
        "sample_weights_full = create_time_weights(len(train), decay_factor=0.95)\n",
        "print(f\"\\nFull data sample weights range: [{sample_weights_full.min():.4f}, {sample_weights_full.max():.4f}]\")\n",
        "\n",
        "# Calculate cutoffs\n",
        "cutoffs = []\n",
        "for config in model_configs:\n",
        "   if config[\"percent\"] == 1.00:\n",
        "       cutoffs.append(0)\n",
        "   else:\n",
        "       cutoff_idx = int(len(train) * (1 - config[\"percent\"]))\n",
        "       cutoffs.append(cutoff_idx)\n",
        "       print(f\"{config['name']} - Using most recent {len(train) - cutoff_idx} samples\")\n",
        "\n",
        "# Cross-validation loop\n",
        "for fold_num, (train_idx, valid_idx) in enumerate(kf.split(train, train['label_bins'])):\n",
        "   print(\"\\n\" + \"#\" * 50)\n",
        "   print(f\"### Fold {fold_num + 1}\")\n",
        "   print(\"#\" * 50)\n",
        "\n",
        "   X_valid = train.iloc[valid_idx][FEATURES]\n",
        "   y_valid = train.iloc[valid_idx][\"label\"]\n",
        "   X_test = test[FEATURES]\n",
        "\n",
        "   # Train each model\n",
        "   for model_idx, (config, cutoff) in enumerate(zip(model_configs, cutoffs)):\n",
        "       print(f\"\\n--- {config['name']} ---\")\n",
        "\n",
        "       if config[\"percent\"] == 1.00:\n",
        "           X_train = train.iloc[train_idx][FEATURES]\n",
        "           y_train = train.iloc[train_idx][\"label\"]\n",
        "           train_weights = sample_weights_full[train_idx]\n",
        "       else:\n",
        "           train_idx_recent = train_idx[train_idx >= cutoff]\n",
        "           train_idx_recent_adjusted = train_idx_recent - cutoff\n",
        "           train_recent = train.iloc[cutoff:].reset_index(drop=True)\n",
        "\n",
        "           X_train = train_recent.iloc[train_idx_recent_adjusted][FEATURES]\n",
        "           y_train = train_recent.iloc[train_idx_recent_adjusted][\"label\"]\n",
        "\n",
        "           sample_weights_recent = create_time_weights(len(train_recent), decay_factor=0.95)\n",
        "           train_weights = sample_weights_recent[train_idx_recent_adjusted]\n",
        "\n",
        "       # Train model\n",
        "       model = xgb.XGBRegressor(**xgb_params, early_stopping_rounds=25)\n",
        "       model.fit(\n",
        "           X_train, y_train,\n",
        "           sample_weight=train_weights,\n",
        "           eval_set=[(X_valid, y_valid)],\n",
        "           verbose=200\n",
        "       )\n",
        "\n",
        "       # Make predictions\n",
        "       if config[\"percent\"] == 1.00:\n",
        "           oof_preds_all[model_idx][valid_idx] = model.predict(X_valid)\n",
        "       else:\n",
        "           valid_idx_in_range = valid_idx[valid_idx >= cutoff]\n",
        "           if len(valid_idx_in_range) > 0:\n",
        "               X_valid_subset = train.iloc[valid_idx_in_range][FEATURES]\n",
        "               oof_preds_all[model_idx][valid_idx_in_range] = model.predict(X_valid_subset)\n",
        "\n",
        "           valid_idx_out_range = valid_idx[valid_idx < cutoff]\n",
        "           if len(valid_idx_out_range) > 0:\n",
        "               oof_preds_all[model_idx][valid_idx_out_range] = oof_preds_all[0][valid_idx_out_range]\n",
        "\n",
        "       test_preds_all[model_idx] += model.predict(X_test)\n",
        "\n",
        "# Average test predictions across folds\n",
        "for i in range(n_models):\n",
        "   test_preds_all[i] /= FOLDS\n",
        "\n",
        "# Calculate individual model scores\n",
        "pearson_scores = []\n",
        "for i, config in enumerate(model_configs):\n",
        "   score = pearsonr(train[\"label\"], oof_preds_all[i])[0]\n",
        "   pearson_scores.append(score)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"INDIVIDUAL MODEL PERFORMANCE (+X174)\")\n",
        "print(\"=\" * 50)\n",
        "for config, score in zip(model_configs, pearson_scores):\n",
        "   print(f\"{config['name']} Pearson Correlation: {score:.4f}\")\n",
        "\n",
        "# Create ensemble predictions\n",
        "ensemble_oof_preds = np.mean(oof_preds_all, axis=0)\n",
        "ensemble_test_preds = np.mean(test_preds_all, axis=0)\n",
        "\n",
        "ensemble_pearson_score = pearsonr(train[\"label\"], ensemble_oof_preds)[0]\n",
        "print(f\"\\nEnsemble (Equal Weight) Pearson Correlation: {ensemble_pearson_score:.4f}\")\n",
        "\n",
        "# Weighted ensemble\n",
        "total_score = sum(pearson_scores)\n",
        "weights = [score / total_score for score in pearson_scores]\n",
        "\n",
        "weighted_ensemble_oof = np.zeros(len(train))\n",
        "weighted_ensemble_test = np.zeros(len(test))\n",
        "\n",
        "for i in range(n_models):\n",
        "   weighted_ensemble_oof += weights[i] * oof_preds_all[i]\n",
        "   weighted_ensemble_test += weights[i] * test_preds_all[i]\n",
        "\n",
        "weighted_ensemble_score = pearsonr(train[\"label\"], weighted_ensemble_oof)[0]\n",
        "print(f\"Weighted Ensemble Pearson Correlation: {weighted_ensemble_score:.4f}\")\n",
        "\n",
        "# Use the better ensemble\n",
        "if weighted_ensemble_score > ensemble_pearson_score:\n",
        "   final_test_preds = weighted_ensemble_test\n",
        "   print(\"\\nUsing weighted ensemble for final predictions\")\n",
        "else:\n",
        "   final_test_preds = ensemble_test_preds\n",
        "   print(\"\\nUsing simple average ensemble for final predictions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Save predictions\n",
        "sample_sub = pd.read_csv('/Users/mahta/Projects/Time-Series-Library/data/drw-crypto-market-prediction/sample_submission.csv')\n",
        "submission = pd.DataFrame({\n",
        "   sample_sub.columns[0]: sample_sub.iloc[:, 0],\n",
        "   'prediction': final_test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_with_X174.csv\", index=False)\n",
        "print(\"\\nSubmission saved to submission_with_X174.csv!\")\n",
        "\n",
        "# Gap-first validation\n",
        "cv_scores = [np.sqrt(np.mean((train[\"label\"] - oof_preds_all[i])**2)) for i in range(n_models)]\n",
        "cv_mean = np.mean(cv_scores)\n",
        "cv_std = np.std(cv_scores)\n",
        "\n",
        "print(f\"\\n=== GAP-FIRST VALIDATION ===\")\n",
        "print(f\"Ensemble Pearson: {weighted_ensemble_score:.4f}\")\n",
        "print(f\"Model RMSE Std: {cv_std:.6f}\")\n",
        "print(f\"Features: {len(FEATURES)} (added back X174)\")\n",
        "\n",
        "if cv_std < 0.01 and weighted_ensemble_score > 0.4:\n",
        "   print(\"‚úÖ SUBMIT: High correlation and stable models\")\n",
        "else:\n",
        "   print(\"‚ö†Ô∏è  CAUTION: Review before submission\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Timeseries Time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Import error: No module named 'exp'\n",
            "Some functionality may be limited, but we'll continue with available components.\n",
            "‚úÖ Time-Series Library setup complete!\n",
            "Available models for benchmarking...\n",
            "Models to benchmark: ['Transformer', 'Informer', 'Autoformer', 'FEDformer', 'TimesNet', 'PatchTST', 'iTransformer', 'Mamba', 'TimeMixer', 'TSMixer', 'Crossformer', 'ETSformer']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Time-Series Transformer Benchmark for Crypto Prediction\n",
        "Let's prepare the data and benchmark multiple transformer models from the library\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "from types import SimpleNamespace\n",
        "import warnings\n",
        "import time\n",
        "import gc\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import the Time-Series-Library modules\n",
        "sys.path.append('/Users/mahta/Projects/Time-Series-Library')\n",
        "\n",
        "# Try to import the required modules with error handling\n",
        "try:\n",
        "    from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
        "    from utils.metrics import metric\n",
        "    from utils.tools import EarlyStopping, adjust_learning_rate\n",
        "    print(\"‚úÖ Time-Series-Library modules imported successfully!\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ö†Ô∏è Import error: {e}\")\n",
        "    print(\"Some functionality may be limited, but we'll continue with available components.\")\n",
        "\n",
        "# Create a custom dataset class for our crypto data\n",
        "class CryptoDataset(Dataset):\n",
        "    def __init__(self, data, seq_len=96, label_len=48, pred_len=24):\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "        self.label_len = label_len  \n",
        "        self.pred_len = pred_len\n",
        "        \n",
        "        # Prepare features (everything except label)\n",
        "        self.features = [col for col in data.columns if col != 'label']\n",
        "        self.data_x = data[self.features].values\n",
        "        self.data_y = data['label'].values.reshape(-1, 1)\n",
        "        \n",
        "        # Normalize the data\n",
        "        self.data_x = (self.data_x - self.data_x.mean(axis=0)) / (self.data_x.std(axis=0) + 1e-8)\n",
        "        self.data_y = (self.data_y - self.data_y.mean()) / (self.data_y.std() + 1e-8)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "        \n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        \n",
        "        # Create dummy time marks (zeros for now)\n",
        "        seq_x_mark = np.zeros((self.seq_len, 1))\n",
        "        seq_y_mark = np.zeros((self.label_len + self.pred_len, 1))\n",
        "        \n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "# Function to create args for different models\n",
        "def create_model_args(model_name, data_info):\n",
        "    args = SimpleNamespace()\n",
        "    \n",
        "    # Basic configuration\n",
        "    args.task_name = 'long_term_forecast'\n",
        "    args.is_training = 1\n",
        "    args.model_id = f'crypto_{model_name}'\n",
        "    args.model = model_name\n",
        "    \n",
        "    # Data configuration\n",
        "    args.data = 'custom'\n",
        "    args.features = 'M'  # Multivariate\n",
        "    args.target = 'label'\n",
        "    args.freq = 't'  # minutely\n",
        "    args.checkpoints = './checkpoints/'\n",
        "    \n",
        "    # Model dimensions\n",
        "    args.seq_len = 96\n",
        "    args.label_len = 48\n",
        "    args.pred_len = 24\n",
        "    args.enc_in = data_info['n_features']\n",
        "    args.dec_in = data_info['n_features'] \n",
        "    args.c_out = 1  # predicting single target\n",
        "    \n",
        "    # Model architecture\n",
        "    args.d_model = 128\n",
        "    args.n_heads = 8\n",
        "    args.e_layers = 2\n",
        "    args.d_layers = 1\n",
        "    args.d_ff = 256\n",
        "    args.dropout = 0.1\n",
        "    args.activation = 'gelu'\n",
        "    args.embed = 'timeF'\n",
        "    args.distil = True\n",
        "    args.factor = 1\n",
        "    args.moving_avg = 25\n",
        "    \n",
        "    # Training configuration\n",
        "    args.batch_size = 64\n",
        "    args.learning_rate = 0.0001\n",
        "    args.train_epochs = 10\n",
        "    args.patience = 3\n",
        "    args.des = f'{model_name}_benchmark'\n",
        "    args.itr = 1\n",
        "    args.loss = 'MSE'\n",
        "    args.lradj = 'type1'\n",
        "    args.use_amp = False\n",
        "    \n",
        "    # Device configuration\n",
        "    args.use_gpu = torch.cuda.is_available()\n",
        "    args.gpu = 0\n",
        "    args.use_multi_gpu = False\n",
        "    args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    # Model-specific parameters\n",
        "    if model_name == 'TimesNet':\n",
        "        args.top_k = 5\n",
        "        args.num_kernels = 6\n",
        "    elif model_name == 'PatchTST':\n",
        "        args.patch_len = 16\n",
        "        args.stride = 8\n",
        "    elif model_name == 'iTransformer':\n",
        "        args.use_norm = 1\n",
        "    elif model_name == 'Mamba':\n",
        "        args.expand = 2\n",
        "        args.d_conv = 4\n",
        "    elif model_name == 'TimeMixer':\n",
        "        args.down_sampling_layers = 3\n",
        "        args.down_sampling_method = 'avg'\n",
        "        args.down_sampling_window = 2\n",
        "    \n",
        "    return args\n",
        "\n",
        "print(\"‚úÖ Time-Series Library setup complete!\")\n",
        "print(\"Available models for benchmarking...\")\n",
        "\n",
        "# List of transformer models to benchmark\n",
        "transformer_models = [\n",
        "    'Transformer', 'Informer', 'Autoformer', 'FEDformer', \n",
        "    'TimesNet', 'PatchTST', 'iTransformer', 'Mamba',\n",
        "    'TimeMixer', 'TSMixer', 'Crossformer', 'ETSformer'\n",
        "]\n",
        "\n",
        "print(f\"Models to benchmark: {transformer_models}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Preparing crypto data for time series modeling...\n"
          ]
        }
      ],
      "source": [
        "# Prepare the data for time series forecasting\n",
        "print(\"üìä Preparing crypto data for time series modeling...\")\n",
        "\n",
        "# Load the data\n",
        "drw_crypto_market_prediction_path = 'data/'\n",
        "train_ts = pd.read_parquet(drw_crypto_market_prediction_path + '/train.parquet')\n",
        "test_ts = pd.read_parquet(drw_crypto_market_prediction_path + '/test.parquet')\n",
        "\n",
        "print(f\"Train data shape: {train_ts.shape}\")\n",
        "print(f\"Test data shape: {test_ts.shape}\")\n",
        "\n",
        "# Use the same features as our XGBoost model\n",
        "selected_features = [\n",
        "    'X863', 'X856', 'X344', 'X598', 'X862', 'X385', 'X852', 'X603', 'X860',\n",
        "    'X415', 'X345', 'X137', 'X855', 'X178', 'X532', 'X168', 'X174',\n",
        "    'bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume'\n",
        "]\n",
        "\n",
        "# Prepare training data\n",
        "train_ts_features = train_ts[selected_features + ['label']].copy()\n",
        "\n",
        "# Create time index (assuming sequential data)\n",
        "train_ts_features = train_ts_features.reset_index(drop=True)\n",
        "\n",
        "# Split into train/val/test for time series (70/15/15 split)\n",
        "n_samples = len(train_ts_features)\n",
        "train_size = int(0.7 * n_samples)\n",
        "val_size = int(0.15 * n_samples)\n",
        "\n",
        "ts_train = train_ts_features[:train_size].copy()\n",
        "ts_val = train_ts_features[train_size:train_size+val_size].copy()\n",
        "ts_test = train_ts_features[train_size+val_size:].copy()\n",
        "\n",
        "print(f\"Time series splits - Train: {len(ts_train)}, Val: {len(ts_val)}, Test: {len(ts_test)}\")\n",
        "\n",
        "# Data info for models\n",
        "data_info = {\n",
        "    'n_features': len(selected_features),\n",
        "    'n_samples_train': len(ts_train),\n",
        "    'n_samples_val': len(ts_val),\n",
        "    'n_samples_test': len(ts_test)\n",
        "}\n",
        "\n",
        "print(f\"Data info: {data_info}\")\n",
        "\n",
        "# Check for any missing values\n",
        "print(f\"Missing values in training data: {ts_train.isnull().sum().sum()}\")\n",
        "if ts_train.isnull().sum().sum() > 0:\n",
        "    print(\"Filling missing values with forward fill...\")\n",
        "    ts_train = ts_train.fillna(method='ffill').fillna(method='bfill')\n",
        "    ts_val = ts_val.fillna(method='ffill').fillna(method='bfill')\n",
        "    ts_test = ts_test.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "print(\"‚úÖ Data preparation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submitting bg_data_prep job...\n",
            "Job submitted: 46092545\n"
          ]
        }
      ],
      "source": [
        "from notebook_utils import submit_cell_as_job\n",
        "\n",
        "# Your cell code as a string\n",
        "cell_code = '''\n",
        "# Prepare the data for time series forecasting\n",
        "print(\"üìä Preparing crypto data for time series modeling...\")\n",
        "\n",
        "# Load the data\n",
        "drw_crypto_market_prediction_path = 'data/'\n",
        "train_ts = pd.read_parquet(drw_crypto_market_prediction_path + '/train.parquet')\n",
        "test_ts = pd.read_parquet(drw_crypto_market_prediction_path + '/test.parquet')\n",
        "\n",
        "print(f\"Train data shape: {train_ts.shape}\")\n",
        "print(f\"Test data shape: {test_ts.shape}\")\n",
        "\n",
        "# Use the same features as our XGBoost model\n",
        "selected_features = [\n",
        "    'X863', 'X856', 'X344', 'X598', 'X862', 'X385', 'X852', 'X603', 'X860',\n",
        "    'X415', 'X345', 'X137', 'X855', 'X178', 'X532', 'X168', 'X174',\n",
        "    'bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume'\n",
        "]\n",
        "\n",
        "# Prepare training data\n",
        "train_ts_features = train_ts[selected_features + ['label']].copy()\n",
        "\n",
        "# Create time index (assuming sequential data)\n",
        "train_ts_features = train_ts_features.reset_index(drop=True)\n",
        "\n",
        "# Split into train/val/test for time series (70/15/15 split)\n",
        "n_samples = len(train_ts_features)\n",
        "train_size = int(0.7 * n_samples)\n",
        "val_size = int(0.15 * n_samples)\n",
        "\n",
        "ts_train = train_ts_features[:train_size].copy()\n",
        "ts_val = train_ts_features[train_size:train_size+val_size].copy()\n",
        "ts_test = train_ts_features[train_size+val_size:].copy()\n",
        "\n",
        "print(f\"Time series splits - Train: {len(ts_train)}, Val: {len(ts_val)}, Test: {len(ts_test)}\")\n",
        "\n",
        "# Data info for models\n",
        "data_info = {\n",
        "    'n_features': len(selected_features),\n",
        "    'n_samples_train': len(ts_train),\n",
        "    'n_samples_val': len(ts_val),\n",
        "    'n_samples_test': len(ts_test)\n",
        "}\n",
        "\n",
        "print(f\"Data info: {data_info}\")\n",
        "\n",
        "# Check for any missing values\n",
        "print(f\"Missing values in training data: {ts_train.isnull().sum().sum()}\")\n",
        "if ts_train.isnull().sum().sum() > 0:\n",
        "    print(\"Filling missing values with forward fill...\")\n",
        "    ts_train = ts_train.fillna(method='ffill').fillna(method='bfill')\n",
        "    ts_val = ts_val.fillna(method='ffill').fillna(method='bfill')\n",
        "    ts_test = ts_test.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "print(\"‚úÖ Data preparation complete!\")\n",
        "\n",
        "'''\n",
        "results = submit_cell_as_job(\n",
        "    cell_code=cell_code,\n",
        "    job_name=\"bg_data_prep\", \n",
        "    output_file='data_prep' + str(time.time()) + '.out',\n",
        "    # account=\"def-gdumas85\"  # or any other account you have access to\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          JOBID     USER      ACCOUNT           NAME  ST  TIME_LEFT NODES CPUS TRES_PER_N MIN_MEM NODELIST (REASON) \n"
          ]
        }
      ],
      "source": [
        "\n",
        "!squeue -u $USER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üõ†Ô∏è Simple transformer benchmark ready!\n"
          ]
        }
      ],
      "source": [
        "# Alternative approach: Simple transformer benchmark using PyTorch directly\n",
        "# This doesn't require the full Time-Series-Library framework\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class SimpleTransformerModel(nn.Module):\n",
        "    \"\"\"A simple transformer model for time series forecasting\"\"\"\n",
        "    def __init__(self, input_dim, d_model=128, nhead=8, num_layers=2, seq_len=96, pred_len=24):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.d_model = d_model\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "        \n",
        "        # Input projection\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "        \n",
        "        # Positional encoding\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(seq_len, d_model))\n",
        "        \n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, \n",
        "            nhead=nhead, \n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        \n",
        "        # Output projection\n",
        "        self.output_projection = nn.Linear(d_model, 1)\n",
        "        \n",
        "        # Prediction head\n",
        "        self.prediction_head = nn.Linear(seq_len, pred_len)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, input_dim)\n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        # Project input to model dimension\n",
        "        x = self.input_projection(x)  # (batch_size, seq_len, d_model)\n",
        "        \n",
        "        # Add positional encoding\n",
        "        x = x + self.pos_encoding.unsqueeze(0)  # Broadcasting\n",
        "        \n",
        "        # Apply transformer\n",
        "        x = self.transformer(x)  # (batch_size, seq_len, d_model)\n",
        "        \n",
        "        # Project to single output dimension\n",
        "        x = self.output_projection(x)  # (batch_size, seq_len, 1)\n",
        "        x = x.squeeze(-1)  # (batch_size, seq_len)\n",
        "        \n",
        "        # Project to prediction length\n",
        "        predictions = self.prediction_head(x)  # (batch_size, pred_len)\n",
        "        \n",
        "        return predictions.unsqueeze(-1)  # (batch_size, pred_len, 1)\n",
        "\n",
        "def run_simple_transformer_benchmark(train_data, val_data, test_data, data_info):\n",
        "    \"\"\"Run a simple transformer benchmark\"\"\"\n",
        "    print(\"üöÄ Running Simple Transformer Benchmark...\")\n",
        "    \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "    \n",
        "    # Prepare data\n",
        "    seq_len, pred_len = 96, 24\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = CryptoDataset(train_data, seq_len=seq_len, pred_len=pred_len)\n",
        "    val_dataset = CryptoDataset(val_data, seq_len=seq_len, pred_len=pred_len)\n",
        "    test_dataset = CryptoDataset(test_data, seq_len=seq_len, pred_len=pred_len)\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
        "    \n",
        "    # Initialize model\n",
        "    model = SimpleTransformerModel(\n",
        "        input_dim=data_info['n_features'],\n",
        "        d_model=128,\n",
        "        nhead=8,\n",
        "        num_layers=2,\n",
        "        seq_len=seq_len,\n",
        "        pred_len=pred_len\n",
        "    ).to(device)\n",
        "    \n",
        "    # Training setup\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    # Training loop\n",
        "    print(\"Training the model...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    model.train()\n",
        "    for epoch in range(5):  # Quick training for benchmark\n",
        "        total_loss = 0\n",
        "        for batch_idx, (batch_x, batch_y, _, _) in enumerate(train_loader):\n",
        "            batch_x = batch_x.float().to(device)\n",
        "            batch_y = batch_y[:, -pred_len:, -1:].float().to(device)  # Last pred_len steps, target feature\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.6f}\")\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "    \n",
        "    # Testing\n",
        "    print(\"Testing the model...\")\n",
        "    test_start = time.time()\n",
        "    \n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y, _, _ in test_loader:\n",
        "            batch_x = batch_x.float().to(device)\n",
        "            batch_y = batch_y[:, -pred_len:, -1:].float()  # Target values\n",
        "            \n",
        "            outputs = model(batch_x).cpu()\n",
        "            \n",
        "            predictions.append(outputs.numpy())\n",
        "            targets.append(batch_y.numpy())\n",
        "    \n",
        "    # Concatenate predictions\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    targets = np.concatenate(targets, axis=0)\n",
        "    \n",
        "    testing_time = time.time() - test_start\n",
        "    \n",
        "    # Calculate metrics\n",
        "    predictions_flat = predictions.flatten()\n",
        "    targets_flat = targets.flatten()\n",
        "    \n",
        "    mse = np.mean((predictions_flat - targets_flat) ** 2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.mean(np.abs(predictions_flat - targets_flat))\n",
        "    \n",
        "    # Calculate correlation\n",
        "    correlation = np.corrcoef(predictions_flat, targets_flat)[0, 1]\n",
        "    \n",
        "    # Model parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    \n",
        "    result = {\n",
        "        'model': 'Simple Transformer',\n",
        "        'mae': mae,\n",
        "        'mse': mse,\n",
        "        'rmse': rmse,\n",
        "        'mape': np.mean(np.abs((targets_flat - predictions_flat) / (targets_flat + 1e-8))) * 100,\n",
        "        'correlation': correlation,\n",
        "        'training_time': training_time,\n",
        "        'testing_time': testing_time,\n",
        "        'total_params': total_params,\n",
        "        'status': 'Success'\n",
        "    }\n",
        "    \n",
        "    print(f\"‚úÖ Simple Transformer completed!\")\n",
        "    print(f\"Correlation: {correlation:.6f}, RMSE: {rmse:.6f}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(\"üõ†Ô∏è Simple transformer benchmark ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting bg_data_prep job... None\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting bg_data_prep job...\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          JOBID     USER      ACCOUNT           NAME  ST  TIME_LEFT NODES CPUS TRES_PER_N MIN_MEM NODELIST (REASON) \n",
            "       46032474    mahta def-gdumas85  crypto_python  PD    8:00:00     1    8 gres:gpu:1     64G  (ReqNodeNotAvail, UnavailableNodes:ng[10101-10104,10201-10204,10301-10304,10401-10404,10501-10504,10601-10610,10701-10712,10801-10808,10901-10906,11001-11006,11101-11106,20101-20104,20201-20204,20301-20303,20403,30601-30605,30701-30712,31001-31006,31101-31104,31201-31205,31301-31305,31401-31402]) \n"
          ]
        }
      ],
      "source": [
        "!squeue -u $USER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è CustomExp class not available - skipping transformer benchmark\n",
            "üõ†Ô∏è  Custom experiment framework ready!\n",
            "Starting transformer benchmark...\n"
          ]
        }
      ],
      "source": [
        "# Custom experiment class to work with our data\n",
        "# Only define if we successfully imported the base class\n",
        "if 'Exp_Long_Term_Forecast' in globals():\n",
        "    class CustomExp(Exp_Long_Term_Forecast):\n",
        "        def __init__(self, args, train_data, val_data, test_data):\n",
        "            super().__init__(args)\n",
        "            self.train_data = train_data\n",
        "            self.val_data = val_data\n",
        "            self.test_data = test_data\n",
        "            \n",
        "        def _get_data(self, flag):\n",
        "            if flag == 'train':\n",
        "                dataset = CryptoDataset(self.train_data, self.args.seq_len, self.args.label_len, self.args.pred_len)\n",
        "            elif flag == 'val':\n",
        "                dataset = CryptoDataset(self.val_data, self.args.seq_len, self.args.label_len, self.args.pred_len)\n",
        "            else:  # test\n",
        "                dataset = CryptoDataset(self.test_data, self.args.seq_len, self.args.label_len, self.args.pred_len)\n",
        "                \n",
        "            data_loader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=self.args.batch_size,\n",
        "                shuffle=(flag == 'train'),\n",
        "                num_workers=0,\n",
        "                drop_last=True\n",
        "            )\n",
        "            \n",
        "            return dataset, data_loader\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è CustomExp class not available - skipping transformer benchmark\")\n",
        "    CustomExp = None\n",
        "\n",
        "def run_single_model_benchmark(model_name, train_data, val_data, test_data, data_info):\n",
        "    \"\"\"Run benchmark for a single model\"\"\"\n",
        "    print(f\"\\\\n{'='*60}\")\n",
        "    print(f\"üöÄ Benchmarking {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Check if required classes are available\n",
        "    if CustomExp is None:\n",
        "        return {\n",
        "            'model': model_name,\n",
        "            'mae': np.nan,\n",
        "            'mse': np.nan,\n",
        "            'rmse': np.nan,\n",
        "            'mape': np.nan,\n",
        "            'correlation': np.nan,\n",
        "            'training_time': np.nan,\n",
        "            'testing_time': np.nan,\n",
        "            'total_params': np.nan,\n",
        "            'status': 'Failed: Time-Series-Library dependencies not available'\n",
        "        }\n",
        "    \n",
        "    try:\n",
        "        # Create model arguments\n",
        "        args = create_model_args(model_name, data_info)\n",
        "        \n",
        "        # Create experiment\n",
        "        exp = CustomExp(args, train_data, val_data, test_data)\n",
        "        \n",
        "        # Create setting name\n",
        "        setting = f'{args.task_name}_{args.model_id}_{args.model}_{args.data}'\n",
        "        \n",
        "        print(f\"‚öôÔ∏è  Training {model_name}...\")\n",
        "        \n",
        "        # Train the model\n",
        "        start_time = time.time()\n",
        "        model = exp.train(setting)\n",
        "        training_time = time.time() - start_time\n",
        "        \n",
        "        print(f\"‚è±Ô∏è  Training completed in {training_time:.2f} seconds\")\n",
        "        \n",
        "        # Test the model\n",
        "        print(f\"üß™ Testing {model_name}...\")\n",
        "        test_start = time.time()\n",
        "        \n",
        "        # Get test predictions\n",
        "        test_data_loader = exp._get_data('test')[1]\n",
        "        preds = []\n",
        "        trues = []\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_data_loader):\n",
        "                batch_x = batch_x.float().to(exp.device)\n",
        "                batch_y = batch_y.float().to(exp.device)\n",
        "                batch_x_mark = batch_x_mark.float().to(exp.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(exp.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(exp.device)\n",
        "                \n",
        "                # prediction\n",
        "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                \n",
        "                # Extract predictions for the target sequence\n",
        "                pred = outputs[:, -args.pred_len:, -1:].detach().cpu().numpy()  # Last feature is target\n",
        "                true = batch_y[:, -args.pred_len:, -1:].detach().cpu().numpy()\n",
        "                \n",
        "                preds.append(pred)\n",
        "                trues.append(true)\n",
        "        \n",
        "        # Concatenate all predictions\n",
        "        preds = np.concatenate(preds, axis=0)\n",
        "        trues = np.concatenate(trues, axis=0)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
        "        \n",
        "        # Calculate correlation (similar to Pearson correlation for our task)\n",
        "        preds_flat = preds.flatten()\n",
        "        trues_flat = trues.flatten()\n",
        "        correlation = np.corrcoef(preds_flat, trues_flat)[0, 1]\n",
        "        \n",
        "        testing_time = time.time() - test_start\n",
        "        \n",
        "        print(f\"‚úÖ {model_name} completed!\")\n",
        "        \n",
        "        return {\n",
        "            'model': model_name,\n",
        "            'mae': mae,\n",
        "            'mse': mse, \n",
        "            'rmse': rmse,\n",
        "            'mape': mape,\n",
        "            'correlation': correlation,\n",
        "            'training_time': training_time,\n",
        "            'testing_time': testing_time,\n",
        "            'total_params': sum(p.numel() for p in model.parameters()),\n",
        "            'status': 'Success'\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error with {model_name}: {str(e)}\")\n",
        "        return {\n",
        "            'model': model_name,\n",
        "            'mae': np.nan,\n",
        "            'mse': np.nan,\n",
        "            'rmse': np.nan, \n",
        "            'mape': np.nan,\n",
        "            'correlation': np.nan,\n",
        "            'training_time': np.nan,\n",
        "            'testing_time': np.nan,\n",
        "            'total_params': np.nan,\n",
        "            'status': f'Failed: {str(e)[:100]}'\n",
        "        }\n",
        "\n",
        "print(\"üõ†Ô∏è  Custom experiment framework ready!\")\n",
        "print(\"Starting transformer benchmark...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'status': 'completed', 'job_name': 'bg_data_prep'}\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'head'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# show the first 5 rows of the results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhead\u001b[49m())\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# show the last 5 rows of the results\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(results.tail())\n",
            "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'head'"
          ]
        }
      ],
      "source": [
        "with open('results.pkl', 'rb') as f:\n",
        "    results = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Starting Transformer Benchmark for Crypto Prediction...\n",
            "============================================================\n",
            "üîß Using Simple PyTorch Transformer approach...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'ts_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîß Using Simple PyTorch Transformer approach...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Run the simple transformer benchmark\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m result = run_simple_transformer_benchmark(\u001b[43mts_train\u001b[49m, ts_val, ts_test, data_info)\n\u001b[32m     52\u001b[39m benchmark_results.append(result)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Also add a simple baseline for comparison\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'ts_train' is not defined"
          ]
        }
      ],
      "source": [
        "# Determine which benchmark approach to use\n",
        "benchmark_results = []\n",
        "\n",
        "print(\"üéØ Starting Transformer Benchmark for Crypto Prediction...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Try the Time-Series-Library approach first\n",
        "if CustomExp is not None:\n",
        "    print(\"üìö Using Time-Series-Library framework...\")\n",
        "    \n",
        "    # Run the benchmark on a subset of models first (to avoid long runtime)\n",
        "    priority_models = [\n",
        "        'Transformer',      # Classic transformer\n",
        "        'Autoformer',       # Popular for time series\n",
        "        'Informer',         # Popular for long sequences  \n",
        "        'DLinear',          # Simple but effective\n",
        "        'PatchTST',         # State-of-the-art for many tasks\n",
        "        'iTransformer',     # Recent improvement\n",
        "        'TimesNet'          # Good general purpose model\n",
        "    ]\n",
        "\n",
        "    print(f\"Models to test: {priority_models}\")\n",
        "\n",
        "    # Run benchmark for each model\n",
        "    for i, model_name in enumerate(priority_models):\n",
        "        print(f\"\\\\n[{i+1}/{len(priority_models)}] Processing {model_name}...\")\n",
        "        \n",
        "        # Run the benchmark\n",
        "        result = run_single_model_benchmark(\n",
        "            model_name, \n",
        "            ts_train, \n",
        "            ts_val, \n",
        "            ts_test, \n",
        "            data_info\n",
        "        )\n",
        "        \n",
        "        benchmark_results.append(result)\n",
        "        \n",
        "        # Clean up memory\n",
        "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "        gc.collect()\n",
        "        \n",
        "        print(f\"Result: {result['status']}\")\n",
        "        if result['status'] == 'Success':\n",
        "            print(f\"Correlation: {result['correlation']:.4f}, RMSE: {result['rmse']:.6f}\")\n",
        "\n",
        "else:\n",
        "    print(\"üîß Using Simple PyTorch Transformer approach...\")\n",
        "    \n",
        "    # Run the simple transformer benchmark\n",
        "    result = run_simple_transformer_benchmark(ts_train, ts_val, ts_test, data_info)\n",
        "    benchmark_results.append(result)\n",
        "    \n",
        "    # Also add a simple baseline for comparison\n",
        "    print(\"\\\\nüîß Adding Linear Regression baseline...\")\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "    \n",
        "    # Prepare data for linear regression\n",
        "    def prepare_linear_data(data, seq_len=96, pred_len=24):\n",
        "        features = [col for col in data.columns if col != 'label']\n",
        "        X, y = [], []\n",
        "        \n",
        "        for i in range(len(data) - seq_len - pred_len + 1):\n",
        "            # Use last value of sequence as features\n",
        "            X.append(data[features].iloc[i + seq_len - 1].values)\n",
        "            # Predict next pred_len values average\n",
        "            y.append(data['label'].iloc[i + seq_len:i + seq_len + pred_len].mean())\n",
        "        \n",
        "        return np.array(X), np.array(y)\n",
        "    \n",
        "    X_train, y_train = prepare_linear_data(ts_train)\n",
        "    X_test, y_test = prepare_linear_data(ts_test)\n",
        "    \n",
        "    # Train linear regression\n",
        "    start_time = time.time()\n",
        "    lr_model = LinearRegression()\n",
        "    lr_model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    # Test\n",
        "    test_start = time.time()\n",
        "    y_pred = lr_model.predict(X_test)\n",
        "    testing_time = time.time() - test_start\n",
        "    \n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    correlation = np.corrcoef(y_test, y_pred)[0, 1]\n",
        "    \n",
        "    lr_result = {\n",
        "        'model': 'Linear Regression Baseline',\n",
        "        'mae': mae,\n",
        "        'mse': mse,\n",
        "        'rmse': np.sqrt(mse),\n",
        "        'mape': np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100,\n",
        "        'correlation': correlation,\n",
        "        'training_time': training_time,\n",
        "        'testing_time': testing_time,\n",
        "        'total_params': X_train.shape[1],  # Number of features\n",
        "        'status': 'Success'\n",
        "    }\n",
        "    \n",
        "    benchmark_results.append(lr_result)\n",
        "    print(f\"Linear Regression - Correlation: {correlation:.6f}, RMSE: {np.sqrt(mse):.6f}\")\n",
        "\n",
        "print(f\"\\\\nüèÅ Benchmark completed! Processed {len(benchmark_results)} models.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Creating Transformer Benchmark Results Table...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'benchmark_results' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìä Creating Transformer Benchmark Results Table...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Convert results to DataFrame\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m results_df = pd.DataFrame(\u001b[43mbenchmark_results\u001b[49m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Sort by correlation (descending) for successful models\u001b[39;00m\n\u001b[32m      8\u001b[39m successful_results = results_df[results_df[\u001b[33m'\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mSuccess\u001b[39m\u001b[33m'\u001b[39m].copy()\n",
            "\u001b[31mNameError\u001b[39m: name 'benchmark_results' is not defined"
          ]
        }
      ],
      "source": [
        "# Create comprehensive benchmark results table\n",
        "print(\"üìä Creating Transformer Benchmark Results Table...\")\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(benchmark_results)\n",
        "\n",
        "# Sort by correlation (descending) for successful models\n",
        "successful_results = results_df[results_df['status'] == 'Success'].copy()\n",
        "if len(successful_results) > 0:\n",
        "    successful_results = successful_results.sort_values('correlation', ascending=False)\n",
        "\n",
        "# Format the results table\n",
        "def format_results_table(df):\n",
        "    \"\"\"Format the results table for better display\"\"\"\n",
        "    formatted_df = df.copy()\n",
        "    \n",
        "    # Round numerical columns\n",
        "    numeric_cols = ['mae', 'mse', 'rmse', 'mape', 'correlation', 'training_time', 'testing_time']\n",
        "    for col in numeric_cols:\n",
        "        if col in formatted_df.columns:\n",
        "            formatted_df[col] = formatted_df[col].round(6)\n",
        "    \n",
        "    # Format parameter count\n",
        "    if 'total_params' in formatted_df.columns:\n",
        "        formatted_df['total_params'] = formatted_df['total_params'].apply(\n",
        "            lambda x: f\"{x:,}\" if not pd.isna(x) else \"N/A\"\n",
        "        )\n",
        "    \n",
        "    return formatted_df\n",
        "\n",
        "# Display results\n",
        "print(\"\\\\n\" + \"=\"*100)\n",
        "print(\"üèÜ TRANSFORMER MODEL BENCHMARK RESULTS - CRYPTO MARKET PREDICTION\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "if len(successful_results) > 0:\n",
        "    print(\"\\\\nüìà SUCCESSFUL MODELS (Ranked by Correlation):\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    formatted_successful = format_results_table(successful_results)\n",
        "    \n",
        "    # Select key columns for display\n",
        "    display_cols = ['model', 'correlation', 'rmse', 'mae', 'training_time', 'total_params']\n",
        "    available_cols = [col for col in display_cols if col in formatted_successful.columns]\n",
        "    \n",
        "    print(formatted_successful[available_cols].to_string(index=False))\n",
        "    \n",
        "    # Highlight best model\n",
        "    best_model = formatted_successful.iloc[0]\n",
        "    print(f\"\\\\nü•á BEST MODEL: {best_model['model']}\")\n",
        "    print(f\"   Correlation: {best_model['correlation']:.6f}\")\n",
        "    print(f\"   RMSE: {best_model['rmse']:.6f}\")\n",
        "    print(f\"   Training Time: {best_model['training_time']:.2f}s\")\n",
        "\n",
        "# Show failed models if any\n",
        "failed_results = results_df[results_df['status'] != 'Success']\n",
        "if len(failed_results) > 0:\n",
        "    print(f\"\\\\n‚ùå FAILED MODELS ({len(failed_results)}):\")\n",
        "    print(\"-\" * 40)\n",
        "    for _, row in failed_results.iterrows():\n",
        "        print(f\"   {row['model']}: {row['status']}\")\n",
        "\n",
        "# Compare with XGBoost baseline\n",
        "print(f\"\\\\nüìä COMPARISON WITH XGBOOST BASELINE:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"XGBoost Ensemble Correlation: {weighted_ensemble_score:.6f}\")\n",
        "\n",
        "if len(successful_results) > 0:\n",
        "    best_transformer_corr = successful_results.iloc[0]['correlation']\n",
        "    print(f\"Best Transformer Correlation: {best_transformer_corr:.6f}\")\n",
        "    \n",
        "    improvement = best_transformer_corr - weighted_ensemble_score\n",
        "    print(f\"Improvement: {improvement:+.6f} ({improvement/weighted_ensemble_score*100:+.2f}%)\")\n",
        "    \n",
        "    if improvement > 0:\n",
        "        print(\"‚úÖ Transformers outperformed XGBoost!\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  XGBoost still leads, but transformers are competitive\")\n",
        "        \n",
        "# Model complexity analysis\n",
        "print(f\"\\\\nüîß MODEL COMPLEXITY ANALYSIS:\")\n",
        "print(\"-\" * 40)\n",
        "if len(successful_results) > 0:\n",
        "    for _, row in successful_results.iterrows():\n",
        "        efficiency_score = row['correlation'] / (row['training_time'] / 60)  # correlation per minute\n",
        "        print(f\"{row['model']:15s} | {row['total_params']:>10s} params | {efficiency_score:.4f} corr/min\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\"*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save benchmark results and create visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Save detailed results to CSV\n",
        "results_df.to_csv('transformer_benchmark_results.csv', index=False)\n",
        "print(\"üíæ Benchmark results saved to 'transformer_benchmark_results.csv'\")\n",
        "\n",
        "# Create summary visualization if we have successful results\n",
        "if len(successful_results) > 0:\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    # 1. Correlation comparison\n",
        "    plt.subplot(2, 3, 1)\n",
        "    models = successful_results['model'].tolist()\n",
        "    correlations = successful_results['correlation'].tolist()\n",
        "    \n",
        "    bars = plt.bar(range(len(models)), correlations, alpha=0.7, color='skyblue')\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Correlation')\n",
        "    plt.title('Model Correlation Comparison')\n",
        "    plt.xticks(range(len(models)), models, rotation=45)\n",
        "    \n",
        "    # Add XGBoost baseline line\n",
        "    plt.axhline(y=weighted_ensemble_score, color='red', linestyle='--', \n",
        "                label=f'XGBoost Baseline ({weighted_ensemble_score:.4f})')\n",
        "    plt.legend()\n",
        "    \n",
        "    # Highlight best model\n",
        "    best_idx = 0\n",
        "    bars[best_idx].set_color('gold')\n",
        "    bars[best_idx].set_alpha(1.0)\n",
        "    \n",
        "    # 2. Training time comparison  \n",
        "    plt.subplot(2, 3, 2)\n",
        "    training_times = successful_results['training_time'].tolist()\n",
        "    plt.bar(range(len(models)), training_times, alpha=0.7, color='lightcoral')\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Training Time (seconds)')\n",
        "    plt.title('Training Time Comparison')\n",
        "    plt.xticks(range(len(models)), models, rotation=45)\n",
        "    \n",
        "    # 3. RMSE comparison\n",
        "    plt.subplot(2, 3, 3)\n",
        "    rmse_values = successful_results['rmse'].tolist()\n",
        "    plt.bar(range(len(models)), rmse_values, alpha=0.7, color='lightgreen')\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title('RMSE Comparison (Lower is Better)')\n",
        "    plt.xticks(range(len(models)), models, rotation=45)\n",
        "    \n",
        "    # 4. Model parameters vs Performance\n",
        "    plt.subplot(2, 3, 4)\n",
        "    params = [int(str(p).replace(',', '')) if isinstance(p, str) else p for p in successful_results['total_params']]\n",
        "    plt.scatter(params, correlations, alpha=0.7, s=100, color='purple')\n",
        "    plt.xlabel('Total Parameters')\n",
        "    plt.ylabel('Correlation')\n",
        "    plt.title('Model Size vs Performance')\n",
        "    \n",
        "    # Add model labels\n",
        "    for i, model in enumerate(models):\n",
        "        plt.annotate(model, (params[i], correlations[i]), \n",
        "                    xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "    \n",
        "    # 5. Efficiency Analysis (Correlation per minute)\n",
        "    plt.subplot(2, 3, 5)\n",
        "    efficiency_scores = [corr / (time/60) for corr, time in zip(correlations, training_times)]\n",
        "    bars = plt.bar(range(len(models)), efficiency_scores, alpha=0.7, color='orange')\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Correlation per Minute')\n",
        "    plt.title('Training Efficiency')\n",
        "    plt.xticks(range(len(models)), models, rotation=45)\n",
        "    \n",
        "    # Highlight most efficient\n",
        "    most_efficient_idx = efficiency_scores.index(max(efficiency_scores))\n",
        "    bars[most_efficient_idx].set_color('darkorange')\n",
        "    bars[most_efficient_idx].set_alpha(1.0)\n",
        "    \n",
        "    # 6. Summary radar chart for top 3 models\n",
        "    plt.subplot(2, 3, 6)\n",
        "    top_3_models = successful_results.head(3)\n",
        "    \n",
        "    if len(top_3_models) >= 2:\n",
        "        # Normalize metrics for radar chart\n",
        "        metrics = ['correlation', 'rmse']\n",
        "        normalized_data = []\n",
        "        \n",
        "        for _, model_row in top_3_models.iterrows():\n",
        "            # Normalize correlation (higher is better)\n",
        "            norm_corr = (model_row['correlation'] - successful_results['correlation'].min()) / (successful_results['correlation'].max() - successful_results['correlation'].min())\n",
        "            # Normalize RMSE (lower is better, so invert)\n",
        "            norm_rmse = 1 - (model_row['rmse'] - successful_results['rmse'].min()) / (successful_results['rmse'].max() - successful_results['rmse'].min())\n",
        "            normalized_data.append([norm_corr, norm_rmse])\n",
        "        \n",
        "        x = range(len(metrics))\n",
        "        for i, (_, model_row) in enumerate(top_3_models.iterrows()):\n",
        "            plt.plot(x, normalized_data[i], 'o-', label=model_row['model'], alpha=0.7)\n",
        "        \n",
        "        plt.xlabel('Metrics')\n",
        "        plt.ylabel('Normalized Score')\n",
        "        plt.title('Top 3 Models Comparison')\n",
        "        plt.xticks(x, ['Correlation‚Üë', 'RMSE‚Üì'])\n",
        "        plt.legend()\n",
        "        plt.ylim(0, 1)\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'Need at least 2 successful models\\\\nfor comparison', \n",
        "                ha='center', va='center', transform=plt.gca().transAxes)\n",
        "        plt.title('Model Comparison')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('transformer_benchmark_visualization.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"üìà Visualization saved as 'transformer_benchmark_visualization.png'\")\n",
        "\n",
        "# Create final summary report\n",
        "print(\"\\\\n\" + \"=\"*80)\n",
        "print(\"üìã FINAL BENCHMARK SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "successful_count = len(successful_results)\n",
        "total_count = len(results_df)\n",
        "\n",
        "print(f\"üéØ Models tested: {total_count}\")\n",
        "print(f\"‚úÖ Successful: {successful_count}\")\n",
        "print(f\"‚ùå Failed: {total_count - successful_count}\")\n",
        "\n",
        "if successful_count > 0:\n",
        "    print(f\"\\\\nüèÜ Best performing model: {successful_results.iloc[0]['model']}\")\n",
        "    print(f\"üìä Highest correlation: {successful_results.iloc[0]['correlation']:.6f}\")\n",
        "    \n",
        "    # Find most efficient model\n",
        "    if len(successful_results) > 1:\n",
        "        efficiency_scores = successful_results['correlation'] / (successful_results['training_time'] / 60)\n",
        "        most_efficient_idx = efficiency_scores.idxmax()\n",
        "        most_efficient_model = successful_results.loc[most_efficient_idx, 'model']\n",
        "        print(f\"‚ö° Most efficient model: {most_efficient_model}\")\n",
        "        \n",
        "    print(f\"\\\\nüí° Key insights:\")\n",
        "    print(f\"   - Average correlation: {successful_results['correlation'].mean():.4f}\")\n",
        "    print(f\"   - Average training time: {successful_results['training_time'].mean():.1f}s\")\n",
        "    print(f\"   - XGBoost baseline: {weighted_ensemble_score:.4f}\")\n",
        "    \n",
        "    # Recommendation\n",
        "    best_corr = successful_results.iloc[0]['correlation']\n",
        "    if best_corr > weighted_ensemble_score:\n",
        "        print(f\"\\\\nüöÄ RECOMMENDATION: Use {successful_results.iloc[0]['model']} for improved performance!\")\n",
        "    else:\n",
        "        print(f\"\\\\nüí≠ RECOMMENDATION: Consider ensemble of transformers + XGBoost for best results\")\n",
        "\n",
        "print(\"\\\\nüéâ Transformer benchmark completed successfully!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "20250531_DRW",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 11418275,
          "sourceId": 96164,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e23729589a149b8bbac5abbaf20bd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0f100293ac544c3e8615e189a4bb8e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "138bfa59102f46deb0686bd14fc7e5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed7260bc8da9460f86f278d4928dd679",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8b0776cbba2e473380bfb98c15a48c0d",
            "value": "You don't have permission to access resource at URL: https://www.kaggle.com/api/v1/hello. The server reported the following issues: Unauthenticated"
          }
        },
        "2d35bccaaaa24a71909163dd2017593d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3828e5a9457d4b808609d568b6aad74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38feef5be5604414a6c53a7955187953": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f90efa390f947df87fa3e976569a9e6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_71c9c27a40da4c6ab8ca86f460e84e5d",
            "value": "Connecting..."
          }
        },
        "3fe743c840564e3db58ca640457c6d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a82705d75f4f9aa7822d814285dbb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68872a6012264841a99b87bc27ef3cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b8b5bab9e4943ebb1c1dda0209ed11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e6679524c3c498e9f8138993d72384e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41a82705d75f4f9aa7822d814285dbb0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d1b2a12b402e412f8ddf62db5c111119",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "71c9c27a40da4c6ab8ca86f460e84e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a8b316e2d7b4871908a75ef41c50657": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8570b29c6c6a48f8872978e6c87833f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6e366575d7f466c8f37731859fc34f2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2d35bccaaaa24a71909163dd2017593d",
            "value": "401 Client Error."
          }
        },
        "86aa95f469d9461bb79fdd7a5caa7105": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89e5aff0f112449992b3cf3470a4e8f8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6b8b5bab9e4943ebb1c1dda0209ed11b",
            "value": "Please make sure you are authenticated if you are trying to access a private resource or a resource requiring consent."
          }
        },
        "89e5aff0f112449992b3cf3470a4e8f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0776cbba2e473380bfb98c15a48c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f90efa390f947df87fa3e976569a9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a532a883232a4de6bb3a93c9542d6ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8570b29c6c6a48f8872978e6c87833f0",
              "IPY_MODEL_138bfa59102f46deb0686bd14fc7e5ed",
              "IPY_MODEL_86aa95f469d9461bb79fdd7a5caa7105"
            ],
            "layout": "IPY_MODEL_dec1fd44a6184e1faa39b606b5bfb073"
          }
        },
        "b34d0672c2ec43ec9c8b4592b0ed93ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_68872a6012264841a99b87bc27ef3cfa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c6f59ff4de904947893cdcf6630fe500",
            "value": ""
          }
        },
        "bb274a4efe3b461381af9c86ac03d4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c52cc0e516344b1694e7fdfe87d5c98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb274a4efe3b461381af9c86ac03d4dd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3828e5a9457d4b808609d568b6aad74a",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "c6f59ff4de904947893cdcf6630fe500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1b2a12b402e412f8ddf62db5c111119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dec1fd44a6184e1faa39b606b5bfb073": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e34d30b7cf4542e2b8e332cf94b18c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3fe743c840564e3db58ca640457c6d4f",
            "style": "IPY_MODEL_0e23729589a149b8bbac5abbaf20bd73",
            "tooltip": ""
          }
        },
        "e363c6fe27ce4aeb8bacea9613786f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7a8b316e2d7b4871908a75ef41c50657",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0f100293ac544c3e8615e189a4bb8e00",
            "value": "mahtaao"
          }
        },
        "e6e366575d7f466c8f37731859fc34f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7260bc8da9460f86f278d4928dd679": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
